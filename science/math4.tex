\section{Analysis, Geometry and Topology}
\subsection{Geometry and Topology}
{\bf Distance and volume in three dimensions:}
$[{\vec a}, {\vec b}, {\vec c}]= {\vec a} \cdot ({\vec b} \times {\vec c})$.
Plane $\Pi$, perpendicular to unit vector ${\vec n}$ and containing ${\vec a}$:
${\vec x} \cdot {\vec n}= {\vec a} \cdot {\vec n} = d$.  Distance from ${\vec y}$ to $\Pi$ is
$| d - {\vec y} \cdot {\vec n}|$.  
${\vec x} \times {\vec y}= (x_2 y_3 - y_2 x_3) {\vec i} +
(x_3 y_1 - y_3 x_1) {\vec j} + (x_1 y_2 - y_1 x_2) {\vec k}$.
Denote $[{\vec a}, {\vec b}]$ as the line from ${\vec a}$ to ${\vec b}$;
$[{\vec {x_0}}, {\vec {x_0}} + {\vec {a}}]= 
\{ {\vec x}: ({\vec x} - {\vec {x_0}}) \times {\vec a} = 0 \}$.  So the line
that includes ${\vec {x_0}}$ and ${\vec {x_1}}$ is
$\{ {\vec x}: ({\vec x} - {\vec {x_0}}) \times ( {\vec {x_1}} - {\vec {x_0}} ) = 0 \}$.  
Denote $[{\vec a}, {\vec b}, {\vec c}]$ as the plane containing ${\vec a}$, ${\vec b}$ and
${\vec c}$. ${\vec a} \times ({\vec b} \times {\vec c})= 
({\vec a} \cdot {\vec c}) {\vec b} - ({\vec a} \cdot {\vec b}) {\vec c}$.
Let $\theta$ be the angle (measured counterclockwise) between $[0,u]$ and
$[0, v]$ then
$\Delta(u,v)= u_1 v_2 - u_2 v_1= |u| |v| sin( \theta)$.
$\Delta(u,v,w)= [u,v,w]=
det \left(
\begin{array}{ccc}
u_1 & u_2 & u_3 \\
v_1 & v_2 & v_3 \\
w_1 & w_2 & w_3 \\
\end{array}
\right)$.  Distance between
$ ({\vec x}- {\vec {x_0}}) \times {\vec a} = 0$ and
$ ({\vec x}- {\vec {x_1}}) \times {\vec b} = 0$ is
${\frac {({\vec {x_0}} - {\vec {x_1}}) \cdot ({\vec a} - {\vec b})}
{||{\vec a} \times {\vec b}||}}$.
\\
\\
{\bf Rotation through $\theta$:}
To transform coordinates: $x' = x cos( \theta ) + y sin( \theta )$, $y' = y cos( \theta ) - x sin( \theta )$.
To rotate a point: $x' = x cos( \theta ) - y sin( \theta )$, $y' = y cos( \theta ) + x sin( \theta )$.
\\
\\
{\bf Moebius Transformations:} 
${\mathbb C}_{\infty}= {\mathbb C} \cup \{ \infty \}$.  ${\cal M}= \{
\tau_{a,b,c,d}(z):
\tau_{a,b,c,d}(z) = {\frac {az+b} {cz+d}}\}$.  If
$\tau_{a,b,c,d}(z)= \tau_{\alpha, \beta, \gamma, \delta}(z)$, $\exists \lambda \in {\mathbb C}$
such that 
$\left(
\begin{array}{cc}
a & b \\
c & d \\
\end{array}
\right) = \lambda
\left(
\begin{array}{cc}
\alpha & \beta \\
\gamma & \delta \\
\end{array}
\right)$.
If $\tau_{a,b,c,d}(z) = {\frac {az+b} {cz+d}}$, $\tau^{-1}(a,b,c,d) = {\frac {dz-b} {a-cz}}$.
If $\tau(z) = {\frac {(\gamma w_1)z+w_2} {\gamma z+1}}$, with $\gamma = {\frac {w_2 - w_3} {w_3 - w_1}}$,
then $\tau(\infty) = w_1$, $\tau(0) = w_2$ $\tau(1) = w_3$.  In the projective plane,
there is always a projective map
that takes three non-colinear points into three arbitrary points non-colinear points, and, in fact,
this determines the projective transformation.
If $\tau \in {\cal M}$, $\tau: {\mathbb C}_{\infty} \rightarrow {\mathbb C}_{\infty}$
and $\tau$ is a product of maps of the following type:
$z \mapsto a z$, $z \mapsto z + b$ and $z \mapsto {\frac 1 z}$.  
For all ordered points,
$\langle z_1, z_2 , z_3 \rangle, 
\langle w_1, w_2 , w_3 \rangle$ in 
${\mathbb C}_{\infty}$, there is a unique $\tau \in {\cal M}$ such that
$\tau(z_i)= w_i$.
For ordered points,
$\langle z_1, z_2 , z_3, z_4 \rangle, 
\langle w_1, w_2 , w_3, w_4 \rangle$ in ${\mathbb C}_{\infty}$, 
there is a $\tau \in {\cal M}$ such that
$\tau(z_i)= w_i$ iff the cross-ratio of 
$[z_1, z_2,z_3,z_4]$ equals the cross ratio of $[w_1, w_2,w_3,w_4]$. 
$\Phi: GL_2({\mathbb C}) \rightarrow {\cal M}$ is a surjective homomorphism given by
$\Phi(
\left(
\begin{array}{cc}
a & b \\
c & d \\
\end{array}
\right) 
)= {\frac {az+b} {cz+d}}$;
the kernel of the homomorphism is $\lambda I, \lambda \in {\mathbb C}$.  The
restriction of $\Phi$ to $SL_2({\mathbb C})$ is also a surjection with kernel $\pm I$.
The \emph{modular group} $SL_2$ is the subset of ${\cal M}$ with $ad-bc=1$ 
with the obvious identification and is generated by 
$\tau \mapsto \tau +1, \tau \mapsto -{\frac 1 {\tau}}$.  Note fundamental region.
Set
$S=
\left(
\begin{array}{cc}
0 & -1\\
1 & 0
\end{array}
\right)
$  and
$T=
\left(
\begin{array}{cc}
1 & 1\\
0 & 1
\end{array}
\right)
$; these correspond to
$S(z)= {\frac {-1} {z}}$ and $T(z)= z+1$.
Define 
$H= \{ z: Im(z)>0 \}$ and
$D= \{ z:  - {\frac 1 2} \leq Re(z) \leq 0, |z|=1 \vee
- {\frac 1 2} \leq Re(z) < {\frac 1 2}, |z|>1 \}$. 
${\cal M}$ maps $H$ into itself and $D$ is a fundamental domain for $SL_2$.
\\
\\
{\bf Spherical triangles:}
$cos(a) = sin(b) sin(c) cos(A) + cos(b) cos(c)$,
${\frac {sin(a)} {sin(A)}}  =  {\frac {sin(b)} {sin(B)}}$.
\\
\\
{\bf Some identities:} 
$cos(Y) - cos(X) = 2 sin({\frac {X+Y} {2}}) sin({\frac {X-Y} {2}})$.
$cos(Y) + cos(X) = 2 cos({\frac {X+Y} {2}}) cos({\frac {X-Y} {2}})$.
$sin(Y) + sin(X) = 2 sin({\frac {X+Y} {2}}) cos({\frac {X-Y} {2}})$.
$sin(X) - sin(Y) = 2 cos({\frac {X+Y} {2}}) sin({\frac {X-Y} {2}})$.
\\
\\
{\bf Daylight:} $cos(\alpha) = - tan(\lambda) tan(\delta)$.  $\lambda$ is latitude. $\delta$ is declination of the sun.
${\frac {2 \alpha} {360}}$ is proportion of $24$ hours.  Example: At peak summer in Seattle, ${\frac {2 \alpha} {360}} = 15.77$ hours.
\\
\\
{\bf Stereographic projection:} $(x, y, z)$ on sphere $(X,Y)$ on plane.  Projected sphere has bottom on $(0,0,0)$.  $t = {\frac {2r}{2r-z}}$.
$tx= X$, $ty=Y$, $x^2 + y^2 + (z-r)^2 = r^2$.  $\beta = {\frac {X^2 + Y^2} {4 r^2}}={\frac {z} {2r-z}}$.
$z= {\frac {2r \beta} {\beta + 1}} = {\frac {X^2 + Y^2} {X^2 + Y^2 + 4 r^2}}$.
\\
\\
{\bf Definition:}
The \emph{circumcenter} is the common intersection of the 3 perpendicular bisectors of
each side of a triangle.
The \emph{incenter} is the common intersection of the 3 angle bisectors of each side
of a triangle.
The \emph{orthocenter} is the intersection of the altitudes.
Angle bisector divides opposite side in proportion to adjacent sides.
The \emph{centroid} is the intersection of the medians.
\\
\\
{\bf Theorems:}  A triangle is divided into six triangles of equal area by the
medians.  The medians of a triangle divide one another in the ratio $2:1$.
The orthocenter, centroid, and circumcenter are collinear.  The centroid divides
the distance from the orthocenter to the circumcenter by the ration of $2:1$.
\begin{quote}
\emph{Proof:}
The medians are concurrent by Ceva's theorem below.  In triangle $ABC$, numbering the sub-trangles
$I, II, III, IV, V, VI$ starting from $A$ and going clockwise. ${\cal A}(I) = {\cal A}(II)$,
${\cal A}(III) = {\cal A}(IV)$, and ${\cal A}(V) = {\cal A}(VI)$.  Also,
${\cal A}(I) + {\cal A}(II) + {\cal A}(III)= {\cal A}(IV) +  {\cal A}(V) + {\cal A}(VI)$, so
${\cal A}(I) = {\cal A}(VI)$.  A similar argument shows ${\cal A}(I) = {\cal A}(III)$.
\end{quote}
{\bf Theorems:}  In triangle $ABC$, (1) let $O$ be the circumcenter, then $OA = OB = OC$;
(2) let $P$ be the incenter, the $d(AB, P) = d(BC, P) = d(AC, P)$.
\begin{quote}
\emph{Proof:}
Again, the altitudes are concurrent by Ceva.  Draw the diagram and use Pythagoras and similar triangles.
\end{quote}
{\bf Pick's Theorem:}  Let $B$ be a polygon which contains
$n_i$ interior lattice points and
$n_b$ lattice points on its boundary. $A(B)= n_i+{\frac {n_b-2} 2}$.
\begin{quote}
\emph{Proof:}
The theorem is true for all right triangles with no interior points in the lattice. 
If the theorem is true for a polygon $P$ and $T$ is a triangle with a single point not in $T$,
the theorem holds for $T \cup P$.
\end{quote}
{\bf Two theorems on triangles:} In triangle $ABC$, suppose $D$ lies on $BC$, $BD=p$,
$CD=q$, then $AD^2= {\frac {pb^2-qc^2} {p+q}} - pq$.  In triangle, $ABC$ suppose the
angle bisector of $A$ meets $BC$ at $D$, $BD=p$ and $CD=q$, then ${\frac {p}{c}}= {\frac {q}{b}}$.
\begin{quote}
\end{quote}
{\bf Definition:}
A \emph{flex} is a non-singular point intersecting P with multiplicity three.  
\\
\\
{\bf Theorem:}  Every irreducible cubic
in the plane has a singular point or a flex.  $H= det([F_{xx}, F_{yx}, F_{zx}]^T, ...)$.
Flex or singular if $H=0$.
\begin{quote}
\end{quote}
Projective points as one dimensional subspaces.  Projective lines are 1 dimensional.
$n_{p \; on \; l} n_l= n_{l \; on \; p} n_p$.
\\
\\
{\bf Fundamental Theorem of Projective Geometry:}  Given three distinct collinear points on each of 
two distinct lines there is a projective transform 
that maps the two sets of points in the specified order.
\begin{quote}
\emph{Proof:}
Define $X = [1,0,0], Y = [0,1,0], Z = [0,0,1], U = [1,1,1]$.
\\
\\
{\bf Lemma:}
If $L =(P,Q,R,S)$ is a list of points of $RP^2$, with no three collinear, then 
there is a unique element of $P(2)$ mapping $(X,Y,Z,U)$ to $L$.
\\
\\
Proof of lemma: Let $P, Q, R, S$ be the $p$-points $[p]$, $[q]$, $[r]$, $[s]$ respectively.
No three of $P,Q,R,S$ are collinear, no three of $p,q,r,s$ are linearly dependent.
Suppose that $t$ is defined by the matrix $A$. 
Then $t(U) = S$ if and only if $[Au] = [s]$, i.e. $Au = \lambda s, \lambda \ne 0$ 
If we replace $A$ by ${\frac 1 {\lambda}}A$, we get the same $t$, so we may assume that $Au = s$
Now, $Ax, Ay, Az$ are just the columns of $A$ (in order), so
$t$ maps $X, Y, Z$ to $P, Q, R$ if and only if the columns of $A$ are 
of the form $\alpha p, \beta q, \gamma r$, with $\alpha, \beta, \gamma \ne 0$.
Also $Au$ is the sum of the columns of $A$ so that $t$ has the required images 
if and only if $\alpha p + \beta q + \gamma r = s$.
Since $p, q, r$ are linearly independent, this has a unique solution $\alpha, \beta, \gamma$.
Since $s$ is not dependent on any two of $p, q, r, \alpha, \beta, \gamma$  are non-zero.
Thus the matrix $A$ with columns $\alpha p, \beta q, \gamma r$ is invertible, so defines an element 
of $P(2)$. From the above argument, $A$ is unique up to scaling, so $t$ is unique.
\\
\\
By the lemma, there exist elements $r, s \in  P(2) $
such that $r$ maps $(X,Y,Z,U)$ to $L$ and $s$ maps $(X,Y,Z,U)$ to $L'$.
Then $t = sr^{-1}$ maps $L$ to $L'$.
Suppose that $u$ also maps $L$ to $L'$. Then $ur$ maps $(X,Y,Z,U)$ to $L'$.
By the uniqueness clause of the Theorem, only $s$ maps $(X,Y,Z,U)$ to $L'$.
Thus $ur = s$, so $u = sr^{-1} = t$, i.e. $t$ is unique.
\end{quote}
{\bf Definition:}
The \emph{cross ratio} of four points is
$r= {\frac {(x_{1}y_{3}-x_{3}y_{1}) (x_{2}y_{4}-x_{4}y_{2})}
{ (x_{1}y_{4}-x_{4}y_{1}) (x_{2}y_{3}-x_{3}y_{2})}}$.
\\
\\
{\bf Theorem:}  Let $ABC$ be a triangle.  The medians are concurrent and divide themselves in
the ratio $1:2$.
\begin{quote}
\emph{Proof:} Let $ABC$ be a triangle and let $F$ be the median from $A$ to $BC$ and
$E$ be the median from $C$ to $AB$; let the medians meet at $G$.
The line $EF$ is parallel to $AC$ $EBF \sim ABC$ and $FEG \sim CGA$ so
$EG:CG = FG : GA = 1:2$.
\end{quote}
{\bf Facts:}
In triangle $ABC$, $AB + BC > AC$; if $A > B$ then $BC > AC$.  A quadrilateral
is cyclic if $ABCD$ lie on a circle. $ABCD$ is concyclic iff $ABC=ADB$.
\\
\\
{\bf Cross ratio from central projection:} Let $O$ be the center 
of a projection onto
a line with projecting lines $OA$, $OB$, $OC$ and $OD$ with $ABCD$ on the line. $r=
{\frac {(CA)(DB)} {(CB)(DA)}}$ is invariant (i.e., if $A', B', C', D'$ are colinear and
$A'$, $B'$, $C'$, $D'$ lie on $OA$, $OB$, $OC$, $OD$, respectively then
$r= {\frac {(C'A')(D'B')} {(C'B')(D'A')}}$).
\begin{quote}
\emph{Proof:} 
$Area(OAC) = {\frac {1} {2}} h CA = {\frac 1 2} (OA)(OC)sin(COA)$,
$Area(OBC) = {\frac {1} {2}} h CB = {\frac 1 2} (OB)(OC)sin(COB)$,
$Area(ODA) = {\frac {1} {2}} h AD = {\frac 1 2} (OA)(OD)sin(AOD)$,
$Area(ODB) = {\frac {1} {2}} h DB = {\frac 1 2} (OB)(OD)sin(BOD)$.
Dividing, we get
${\frac {(CA)(DB)} {(CB)(DA)}} = {\frac {sin(COA) sin(BOD)} {sin(BOC) sin(AOD)}}$.
\end{quote}
{\bf Desargues:} If $ABC$ and $A'B'C'$ are perspective from a point $X$, then
$AB \cap A'B' = P$, $AC \cap A'C' = Q$, $BC \cap B'C' = R$
are collinear.
\begin{quote}
\emph{Proof:}
Let $ABC$ and $abc$ are the two triangles with $Aa$, $Bb$, $Cc$ concurrent.
$A, B, a, b$ are co-planar so $AB$ and $ab$ intersect.  If both triangles
are on different planes, $(AB) \cap (ab)$ is in both planes and so are
$(AC) \cap (ac)$ and $(BC) \cap (bc)$  and $(BC) \cap (bc)$.  These planes
intersect in a line, proving the theorem.
\end{quote}
{\bf Pappus:} If $ABC$ is on $L$ and $A'B'C$' is on $L'$, then
$AB' \cap A'B = P$, $AC' \cap A'C = Q$, $CB' \cap C'B = R$ are collinear. 
\begin{quote}
\emph{Proof:} See proof below.
\end{quote}
{\bf Ptolemy's Theorem:} Let $ABCD$ be a cyclic quadrilateral (vertices lie
on a circle).  Then $AB \cdot CD + AD \cdot BC = AC \cdot BD$.
\begin{quote}
\emph{Proof:}
$CAB = BDC$ and $ADB = BCA$.  Draw a line from point $K$ to the line $AC$ so that $ABK = DBC$.
$\Delta ABK \cong \Delta DBC$ and $\Delta ABD \cong \Delta KBC$,
${\frac {AK} {AB}} = {\frac {CD} {BD}}$ and ${\frac {CK} {BC}} = {\frac {AD} {BD}}$.
Thus $(AC)(BD) = (AK)(BD) +(CK)(BD) = (AB)(CD) + (BD)(DA)$.
\end{quote}
{\bf Pascal:}
Suppose a hexagon is inscribed in a conic section,  
and opposite pairs of sides are extended until they meet in 5 points. Then if 
4 of those points lie on a common line, the last point will be on that line, too. 
\begin{quote}
See proof below.
\end{quote}
{\bf Menelaus and Ceva:} (1) If points $X, Y, Z$ on $BC, CA, AB$ (suitably extended) are collinear
then $\frac {AZ} {ZB} \frac {BX} {XC} \frac {CY} {YA}  = 1$.  Similarly, (2)
$ABC$ with $X$ opposite $A$. $AX, BY, CZ$ are concurrent iff
$\frac {AZ} {ZB} \frac {BX} {XC} \frac {CY} {YA}  = 1 $.
\begin{quote}
\emph{Proof:} 
Rotate so that the line $XYZ$ is horizontal.  Drop perpendiculars from $A, B, C$ respectively to this
line with heights $h_1, h_2, h_3$, respectively.  By similar triangles,
${\frac {AY}{CY}} = {\frac {h_1} {h_3}}$,
${\frac {BZ}{AZ}} = {\frac {h_2} {h_1}}$, and
${\frac {CX}{BX}} = {\frac {h_3} {h_2}}$.  Multiply them together to get (1).
For (2), note that
${\frac {AZ}{BZ}}= {\frac {|APZ|} {|BPZ|}}$,
${\frac {CY}{AY}}= {\frac {|CPY|} {|APY|}}$, and
${\frac {BX}{CX}}= {\frac {|BPX|} {|CPX|}}$.
Also,
${\frac {AZ}{BZ}}= {\frac {|AZC|} {|BZC|}}$,
${\frac {CY}{AY}}= {\frac {|CYB|} {|AYB|}}$, and
${\frac {BX}{CX}}= {\frac {|AXB|} {|AXC|}}$.
Thus,
${\frac {BX} {CX}}= {\frac {|ABX|-|BPX|}{|ACX|-|CPX|}}= {\frac {|APB|} {|APC|}}$,
${\frac {CY} {AY}}= {\frac {|BPC|} {|BPA|}}$, and
${\frac {AZ} {BZ}}= {\frac {|APC|} {|BPC|}}$.
Multiplying these together we get the result.
\end{quote}
{\bf Projective geometry with complex numbers:}  Points are $z \in {\mathbb C}$ and $\infty$.  Cross ratio is 
$C(z_1, z_2; z_3, z_4) = {\frac {(z_1 - z_3)(z_2 - z_4)}{(z_1-z_4)(z_2-z_3)}}$.  Four points lie on a line (or circle) iff their
cross ratio is a real number.  Moebius Transformation: $f_{a,b,c,d}(z) = {\frac {az+b} {cz+d}}$, $ad-bc \ne 0$.
If a moebius transformation takes four points $(z_1, z_2, z_3, z_4) \mapsto (u_1, u_2, u_3, u_4)$ then
$C(z_1, z_2; z_3, z_4) = C(u_1, u_2; u_3, u_4)$.
Use the fact that $f_{a,b,c,d}(z) - f_{a,b,c,d}(w) = {\frac {(ad-bc)(z-w)}{(cz+d)(cw+d)}}$.
If $C(z_1, z_2; z_3, z_4) = C(u_1, u_2; u_3, u_4)$, there is a moebius transformation that maps $(z_1, z_2, z_3, z_4) \mapsto (u_1, u_2, u_3, u_4)$.
\\
\\
{\bf Spherical Geometry:}  Let $PQR$ be a spherical triangle with subtended angles
$p, q, r$ on a sphere of radius $R$.  The area of $PQR$ is $R^2(p+q+r-\pi)$.
\begin{quote}
\emph{Proof:} Let $P', Q', R'$ be the antipodal points of $P, Q, R$ respectively and
$C_P, C_Q, C_R$ be the great circles containing $PP'$, $QQ'$ and $RR'$ respectively.
Let $\Delta_C$ be the common area of the three great circles in the hemisphere containing
$P, Q, R$ which forms the spherical triangle.  If $\Lambda(C_P, C_Q)$ 
is the lune formed by the intersection of the great circles, set 
$\Delta_1= \Lambda(C_P, C_Q) - \Delta_C$,
$\Delta_2= \Lambda(C_P, C_R) - \Delta_C$,
$\Delta_3= \Lambda(C_R, C_Q) - \Delta_C$, and let
$\Delta_C'$, $\Delta_1'$, $\Delta_2'$, and
$\Delta_3'$ be the corresponding antipodal areas.  
$\Delta_C+ \Delta_1+ \Delta_2+ \Delta_3= \Delta_C'+ \Delta_1'+ \Delta_2'+ \Delta_3'$,
and
$\Delta_C+ \Delta_1+ \Delta_2+ \Delta_3+\Delta_C'+ \Delta_1'+ \Delta_2'+ \Delta_3'
=4 \pi R^2$ (``EQ 1''), so
$\Delta_C+ \Delta_1+ \Delta_2+ \Delta_3= 2 \pi R^2$.  Further,
$\Delta_C + \Delta_1= 2 R^2 p$, $\Delta_C + \Delta_2= 2 R^2 r$, and
$\Delta_C + \Delta_3= 2 R^2 q$ so
$3\Delta_C+ \Delta_1+ \Delta_2+ \Delta_3 = 2 R^2 (p+q+r)$, 
subtracting EQ 1 from this and dividing by $2$ gives the desired result.
\end{quote}
{\bf Euler's Formula}: $V-E+F= \chi$. For a sphere, $\chi=2$.
Let $n_i$: number of vertices with valence $i$, $2e \geq 3F$, $\sum in_i = 2E$.
\\
\\
{\bf Solid angle subtended by cone:} If a cone with apex at center of sphere has apex angle $\theta$,
$\Omega = 4 \pi sin^2({\frac {\theta} 2})$.
\\
\\
{\bf Differential Geometry:}
Curve length: $s(t)= \int_{t_0}^t | \gamma'(t)| dt$.  Let $'$ be differentiation with respect to
$s$.
${\vec T} (s)=  {\vec x(s)}'$.  ${\vec T} (s)$ is a unit vector. ${\vec N (s)} = {\frac {{\vec T} (s)'}
{|{\vec T} (s)'|}}$.  ${\vec N (s)}$ is also a unit vector called the \emph{normal}.  $\kappa(s)= |{\vec T} (s)'|$
is the curvature.  The \emph{binormal} is ${\vec B(s)} = {\vec T} (s) \times {\vec N (s)}$.  The \emph{torsion} is
$\tau(s)$ where  ${\vec B(s)}' = -\tau(s)  {\vec N (s)}$.  Frenet formulas are:
${\vec T (s)}' = \kappa(s) {\vec N(s)}$, 
${\vec B (s)}' = -\tau(s){\vec N(s)}$, 
${\vec N (s)}' = -\kappa(s) {\vec T(s)} + \tau(s) {\vec B(s)}$.
First Fundamental Form: 
If $E= {\vec {x_u}} \cdot {\vec {x_u}}$,
$F= {\vec {x_u}} \cdot {\vec {x_v}}$ and
$G= {\vec {x_v}} \cdot {\vec {x_v}}$ then $I(du, dv)= E du^2 + 2F du dv + G dv^2$.
If ${\vec N}= {\frac { {\vec {x_u}} \times {\vec {x_v}} }
{| {\vec {x_u}} \times {\vec {x_v}} |} }$ then
$L= -{\vec {x_u}} \cdot {\vec {N_u}}$,
$M= -{\frac 1 2}(
{\vec {x_u}} \cdot {\vec {N_v}} + {\vec {x_v}} \cdot {\vec {N_u}})$,
$N= -{\vec {x_v}} \cdot {\vec {N_v}}$ and $II(du,dv)= L du^2 + 2M du dv +N dv^2$.
$\kappa_n= {\frac {II} {I}}$.  $\kappa$ is a principal curvature iff
$det \left(
\begin{array}{cc}
L- \kappa E &  M - \kappa F \\
M - \kappa F &  N - \kappa G
\end{array}
\right) =0$.  
If $f(x)=0$ defines surface, $H(f)= ({\frac {\partial^2 f} {\partial x_i \partial x_j}})$.
\emph{Gaussian curvature}: $det(H(f))$.
If a surface is represented by ${\vec r}(u,v)$ for $(u,v) \in {\cal R}$ then
$A(S)= \int_{{\cal R}} 
|{\frac {\partial {\vec r}} {\partial u}} \times
{\frac {\partial {\vec r}} {\partial v}}| \thinspace du \thinspace dv
$.  \emph{Torus:} ${\vec r}( \theta, \phi)= (
(R+r cos(\phi)) cos(\theta),
(R+r cos(\phi)) sin(\theta), R sin(\phi)) $.  $A(S)= 4 \pi^2 rR$.
\\
\\
{\bf Model for Hyperbolic Geometry:}
${\cal H}= \{ x+yi: y>0 \}$ is the \emph{hyperbolic plane}.  \emph{Hyperbolic lines} are
semicircles with centers on the real axis.  Mobieus transformations fix ${\cal H}$ and
map hyperbolic lines to hyperbolic lines. If $[a,b,c,d]$ is the cross ratio, the hyperbolic distance between
$z_1$ and $z_2$ is $log([u,z_1, z_2, v])$ where $u$ and $v$ are the endpoints on the real line of
the hyperbolic line joining $z_1$ and $z_2$.  If a hyperbolic right trainagle consists of lines
of length $a, b, c$, $cosh(c)= cosh(a) \cdot cosh(b)$.  Any bijection mapping circles into cirlces is
a Mobieus transformation on $z$ or ${\overline z}$.
\\
\\
{\bf Gaussian curvature:} If $k_1$ and $k_2$ are the maximum and minimum values
of the curvature at a point on a surface, the Gaussian curvature is $K= k_1 k_2$;
$\chi=2-2g$ is the Euler characteristic, where $g$ is the genus.  $k_1$ and $k_2$ are
also eigenvalues of the \emph{Hessian}.
The \emph{genus} of a connected, orientable surface is an 
integer representing the maximum number of cuttings along closed simple curves without 
rendering the resultant manifold disconnected and it is equal to the number 
of handles on it. 
\\
\\
{\bf Gauss-Bonnet:}  If X is a compact, hypersurface in ${\mathbb R}^{k+1}$, then
$\int_X K = Vol( S^k ){\frac {\chi (X)} {2}}$.
\\
\\
{\bf Eight Point Theorem:}
Suppose $C$ is a curve in ${\mathbb P}^2_K$ defined by 
homogeneous cubic polynomial $C(x,y,z)=0$.
Let $l_1, l_2, l_3$ and $m_1, m_2, m_3$ be lines in ${\mathbb P}^2_K$ with 
$l_i \ne m_j, \forall i,j$ and $P_{ij}= l_i \cap m_j$.  Suppose further that $C$ is not
singular at $P_{ij}, \forall i,j \ne 3,3$.  Then $P_{33} \in C$.
This is proved in a series of lemmas. \emph{Lemma 1:} Let $P_{i1}=(u_i : v_i)$ 
and $m_j : a_j x +b_j y +c_j z=0$, 
${\overline {m_j}} (u_i, v_i) = 0$ and
${\overline {m_j}}$ vanishes only at $P_{ij}$.
${\overline {m_1}} (u,v) {\overline {m_2}} (u,v) {\overline {m_3}} (u,v)$
is a homogeneous cubic polynomial.   
\emph{Lemma 2:} If $R(u,v), S(u,v)$ are homogeneous of
degree $3$ and is not identically $0$ and they both vanish at $(u_i:v_i)$ then 
$\exists  \alpha \in K, \alpha \ne 0$: $R = \alpha S$.  
\emph{Lemma 3:}
${\overline C}= \alpha {\overline {m_1}} (u,v) {\overline {m_2}} (u,v) {\overline {m_3}} (u,v)$
and
${\overline C}= \alpha {\overline {l_1}} (u,v) {\overline {l_2}} (u,v) {\overline {l_3}} (u,v)$.
\emph{Lemma 4:}  $l_i \mid (C - \alpha m_1 (u,v) m_2 (u,v) m_3 (u,v))$,
$m_j \mid (C - \beta l_1(u,v) l_2 (u,v) l_3 (u,v))$ and
if $D= C - \alpha m_1 (u,v) m_2 (u,v) m_3 (u,v) - \beta l_1 (u,v) l_2 (u,v) l_3 (u,v)$, then
$l_i m_ j \mid D$.  
\emph{Lemma 5:} $D = l_1 m_1 l(u,v)$ and
$l(P_{22})= l(P_{23})= l(P_{32})=0$, so $D=0$.  To conclude the proof of the
eight point theorem, observe, since $D=0$, 
$C= \alpha m_1 (u,v) m_2 (u,v) m_3 (u,v) + \beta l_1 (u,v) l_2 (u,v) l_3 (u,v)$ and
$l_3 (P_{33})= m_3 (P_{33}) =0$ thus $C (P_{33})=0$.
\\
\\
{\bf The eight point theorem proves associativity of elliptic curve addition:}
Let $P, Q, R$ be points
on $C$ and consider
$l_1= {\overline {P,Q}}$,
$l_2= {\overline {\infty,Q+R}}$,
$l_3= {\overline {R,P+Q}}$,
$m_1= {\overline {Q,R}}$,
$m_2= {\overline {\infty,P+Q}}$,
$m_3= {\overline {P,R+Q}}$.
$l_1 \cap m_1= Q$,
$l_1 \cap m_2= -(P+Q)$,
$l_1 \cap m_3= P$,
$l_2 \cap m_1= -(Q+R)$,
$l_2 \cap m_2= \infty$,
$l_2 \cap m_3= Q+R$,
$l_3 \cap m_1= R$,
$l_3 \cap m_2= (P+Q)$,
$l_3 \cap m_3= X$. $X$ is $-((P+Q)+R)$ (from the definition of $l_3$) and $-(P+(Q+R))$ 
(from the definition of $m_3$) by the definition of addition.  Now
apply the eight point theorem to get the result.
\\
\\
The eight point theorem also proves {\bf Pascal's Theorem:}
Let $ABCDEF$ be a hexagon inscribed in a
conic section whose equation is $Q(x,y,z)=0$.  If 
$X= {\overline {AB}} \cap  {\overline {DE}}$,
$Y= {\overline {BC}} \cap  {\overline {EF}}$,
$Z= {\overline {CD}} \cap  {\overline {FA}}$, then $X, Y, Z$ are collinear.  
\begin{quote}
\emph{Proof:}
Put
$l_1 = {\overline {EF}}$,
$l_2 = {\overline {AB}}$,
$l_3 = {\overline {CD}}$,
$m_1 = {\overline {BC}}$,
$m_2 = {\overline {DE}}$,
$m_3 = {\overline {FA}}$, $C(x,y,z)= Q(x,y,z)l(x,y,z)$ and apply the theorem. 
\end{quote}
This also proves {\bf Pappus's Theorem:} Let $l, m$ be two distinct lines $A,B,C$ on $l$ and
$A', B', C'$ on $m$ none of which are on $l \cap m$.  If
$X= {\overline {AB'}} \cap  {\overline {A' B}}$,
$Y= {\overline {BC'}} \cap  {\overline {B'C}}$,
$Z= {\overline {CA'}} \cap  {\overline {C'A}}$, then $X, Y, Z$ are collinear.  \emph{Proof:}
Use Pascal with hexagon $AB'CA'BC'$.
\\
\\
{\bf Definition:}
Let $\Phi: Q \rightarrow P$ be a \emph{homotopy} of $\varphi_0$ into $\varphi_1$ as closed
curves and let $y \notin \Phi(Q)$.  Then the \emph{winding number}
$W(\varphi_r, y)$ is constant
for $0 \le r \le 1$.  Let $\varphi$ be a closed curve $\varphi: [a,b] \rightarrow P$ and
suppose $y_0 , y_1$ can be joined by a curve which does not intersect $\varphi$, then
$W(\varphi, y_0 )= W(\varphi , y_1)$.  Let $f: D \rightarrow P$ be a mapping of
the disk onto the plane and let $C= \partial D$ and let $y \notin f(C)$;
if the winding number
of $f|C$ about $y$ is not zero, then $y \in f(D)$ such that $f(x)=y$.
Let $f: D \rightarrow P$ be a mapping of a disk onto a plane, $P$ and $C= \partial D$
that fixes all of $C$ then $D \subseteq f(D)$.  No mapping of a disk onto its boundary
fixes each point of the boundary.  If $f$ is a mapping of a disk onto itself, it has
a fixed point. 
\\
\\
{\bf Theorem:}
A finite group of transformations over ${\mathbb R}^3$ has fixed points. $|G|= v_p n_p$,
$2(|G| -1) = \sum_p (v_p - 1)$.
\\
\\
{\bf Reflections:}  Reflection in the line of slope $m$
$R_m = 
\left(
\begin{array}{cc}
{\frac {1 - m^2} {1+m^2}} & {\frac {2 m} {1+m^2}} \\
{\frac {2 m} {1+m^2}} & {\frac {m^2 - 1} {1+m^2}} \\
\end{array}
\right)$. \\
$R_{m_2} R_{m_1} = 
\left(
\begin{array}{cc}
{\frac {(m_1 m_2 +1)^2 - (m_1 - m_2)^2} {(1+{m_1}^2) (1+{m_2}^2)}} & 
{\frac {2(m_1 - m_2 )(1+ m_1 m_2)} {(1+{m_1}^2) (1+{m_2}^2)}}  \\
{\frac {2(m_2 - m_1 )(1+ m_1 m_2)} {(1+{m_1}^2) (1+{m_2}^2)}} &
{\frac {(m_1 m_2 +1)^2 - (m_1 - m_2)^2} {(1+{m_1}^2) (1+{m_2}^2)}} \\
\end{array}
\right)$.  A reflection in the line with slope ${\theta_1}$ followed by one of slope ${\theta_2}$ is
equivalent to a rotation in $2(\theta_1 - \theta_2)$.
\subsection {Real Analysis and Manifolds}
{\bf Definition:} A metric space, $R$, is a vector space with a distance
$d: R \times R \rightarrow {\mathbb R}^{\ge 0}$,
such that $d(x,x) = 0$ iff $x = 0$ and $\forall x, y, z \in R$, $d(x,z) \leq d(x, y) + d(y, z)$.
$B_r(c) = \{ x: d(x,c) \leq r \}$
\\
\\
{\bf Definition:} A set $S \subseteq R$ in a metric space $R$ is open if $\forall x \in R, \exists \epsilon > 0:
B_{\epsilon} \subseteq S$.  $T$ is a closed set if $R \setminus S$ is open.  A subset $S \subseteq R$ if every
open cover of $S$ contains a finite subcover of $S$.
\\
\\
{\bf Theorem:} (a) $S$ is compact iff $S$ is closed and bounded; (b) $[a, b]$ is compact;
(c) if $f$ is continuous, $f([a,b])$ is compact; (d) if $S$ is closed and
$lim_{n \rightarrow \infty} x_n = a, x_n \in S$ then $a \in S$.
\begin{quote}
\emph{Proof:}
(a, $\rightarrow$) Suppose $S$ is a compact set and suppose ${\overline S}$ is not open.  There is a point
$X \in {\overline S}$ which contains no open ball, $B_r(X)$.  Let $R_x = \{y \in S: d(x,y) < {\frac 
{d(x, X)} 2}$ then $\{R_x, x \in S \}$ is an open cover of $S$ with no finite subcover, so
no such $X$ exists and ${\overline S}$ is open so $S$ is closed.  If $S$ is not bounded then
$R_{x, n} = \{ y \in S: d(x,y) < n \}$, $\{R_{x, n}, x \in S n \in {\mathbb Z} \}$
is an open cover with no finite subcover so $S$ must be bounded. (a, $\leftarrow$) Suppose $S$
is a closed, bounded set which is not compact and let $U$ be an open cover of $S$.  Since
$S$ is bounded there are a finite number of closed balls ${\overline {B_{\frac 1 2}(a_i)}}, a =
1, 2, \ldots, k$.  At least one of $S_1 = S \cap {\overline {B_{\frac 1 2}(a_i)}}$, say
${\overline {B_{\frac 1 2}(a_j)}}$, which does not have a finite subcover.  Repeating this argument,
with $S_2 = {\overline {B_{\frac 1 4}(a_j)}},  \ldots , S_k{\overline {B_{\frac 1 {2^k}}(a_j)}}, \ldots ,$.
$S_1 \supseteq S_2 \supseteq \ldots$.  The common interesection contains a point $p \in S$.  Since
$U$ contains an open subset $T$, $p \in T$, the chain of subsets terminates after finitely many
terms contradicting the assumption that no finite subcover exists.
(b) $[a,b]$ is closed and bounded and the result follows from (a). (c) If $U$ is a cover of
$f([a,b])$; then $W = \{f^{-1}(X), X \in U \}$ is a cover of $[a,b]$, so there is a finite 
subcover $W_1 \subseteq W$ but then $\{f(Y), Y \in W_1 \}$ is a finite cover of $f([a,b])$.
(d) If $lim_{n \rightarrow \infty} x_n = a, x_n \in S$ then any open set containing $a$
has a non trivial intersection with $S$ and so ${\overline S}$ is not open if $a \in {\overline S}$.
\end{quote}
{\bf Theorem:} If $f$ is continuous on $[a,b]$ and $f(a)=f(b)$ then $f$ attains a maximum (minimum) at some point,
$c: a<c<b$ and if $f$ is differentiable, $f'(c)=0$.
$\exists \xi, a < \xi < b$ such that $f'(\xi)= {\frac {f(b)-f(a)} {b-a}}$.
\begin{quote}
\emph{Proof:} Set $g(x)= f(x)-[({\frac {f(b)-f(a)}{b-a}}) (x-a) + f(a)]$.  $g(a)=g(b)=0$ and there is a
$a<\xi<b$ on which $g$ attains a maximum or minimum. $g'(\xi)= 0 = f'(\xi) - {\frac {f(b)-f(a)}{b-a}}$.
\end{quote}
{\bf Definition:} $f$ is \emph{convex upwards} (resp \emph{convex downwards}) on $[a,b]$ if 
$f(at+(1-t)b) \leq tf(a)+(1-t)f(b)$ for $0 \leq t \leq 1$
(resp.  $f(at+(1-t)b) \geq tf(a)+(1-t)f(b)$ for $0 \leq t \leq 1$).
\\
\\
{\bf Theorem:} If $f''(x) > 0$ (resp $f''(x)<0$, $a \leq x \leq b$) then $f$ is 
convex upwards (resp convex downwards).
\begin{quote}
\emph{Proof (convex backwards):} Put $g(t)= f(ta+(1-t)b)-tf(a)+(x-1)f(b)$.  $g(0)=g(1)=0$.
$g''(t)= (a-b)^2f''(ta+(1-t)b)$.  If $g$ has a local minumum at $t_0$,
$g(t_0)= 0$ and $g''(t_0)>0$.  This is a contradiction so the minumum of $g, 0 \leq t \leq 1$
occurs at the endpoints and the result holds.
\end{quote}
{\bf Definition} A space is connected iff it cannot be written as a disjoint union of
relatively open sets.
\\
\\
{\bf Theorem:} If $f$ is continuous and $E$ is a connected space, so is $f(E)$.
\begin{quote}
\emph{Proof:} Suppose $f(E)= X \cup Y$, then $f^{-1}(X) \cup f^{-1}(Y) = f(E)$ and they
are disjoint, relatively open sets.
\end{quote}
{\bf Theorem:} If $\varphi$ is strictly increasing and $\varphi: [A,B] \rightarrow [a,b]$ and $\alpha$ is also
increasing on $[a,b]$, set $\beta(y)= \alpha(\varphi(y))$ and $g(y)= f(\varphi(y))$ then
$\int_A^B g \; d \beta = \int_a^b f \; d \alpha$.
\begin{quote}
\end{quote}
{\bf Fundamental Theorem of Calculus:}   Suppose $f$ is integrable on $[a,b]$ and define
$F(x)= \int_a^x f(t) \; dt$ 
then for $a \leq c \leq b$, we have $F'(c)= f(c)$ and $\int_a^b f(t) \; dt = F(b)-F(a)$.
\begin{quote}
\emph{Proof:}
$F(x+h) - F(x) = \int_{x}^{x + h} f(x) dx$, $\exists c: x \leq c \leq x+h: \int_{x}^{x + h} f(x) dx =h f(c)$.
So $lim_{h \rightarrow 0} {\frac {F(x+h) - F(x)} {h}} = f'(x)$.
\end{quote}
{\bf Definition:} 
A sequence $\{ f_n \}$ converges \emph{uniformly} on $E$ to $f$ if $\forall \epsilon >0, \exists N: n>N,
|f(x) - f_n(x)| < \epsilon$.
A family ${\cal F}$ is \emph{equicontinuous} on $E$ if $\forall \epsilon > 0, \exists \delta >0:
|f(x)-f(y)| < \epsilon$ if $|x-y| < \delta, \forall f \in {\cal F}$.
\\
\\
{\bf Theorem:} If a sequence of continuous functions $\{ f_n \}$ converges uniformly to $f$ on $E$ then
$f$ is continuous on $E$.
\begin{quote}
\emph{Proof:} Choose $N: \forall n \geq N, |f_n(x) - f(x)| < {\frac {\epsilon} {3}}$ and choose 
$\delta > 0: |f_n(x+h) - f_n(x)| < {\frac {\epsilon} {3}}$.
$|f(x+h) - f(x)| \leq |f_n(x + h) - f(x + h)| + |f_n(x) - f(x)| + |f_n(x+h) - f_n(x)| < \epsilon$ for
the chosen $\delta$.
\end{quote}
{\bf Theorem:} If $K$ is compact and a sequence of continuous functions $\{ f_n \}$
converges pointwise to $f$ on $K$
and if $f_n(x) \geq f_{n+1}(x)$ then $\{ f_n \}$ converges \emph{uniformly} on $K$.
\begin{quote}
\end{quote}
{\bf Theorem:} If $K$ is compact and $\{ f_n \}$ converges uniformly then $\{ f_n \}$ is equicontinuous.
\begin{quote}
\end{quote}
{\bf Theorem:} If $K$ is compact and $\{ f_n \}$ converges pointwise on $K$ then $\{ f_n \}$ is uniformly
bounded and $\{ f_n \}$ contains a uniformly convergent subsequence.
\begin{quote}
\end{quote}
{\bf Stone Weierstrauss Theorem:} If $f$ is continuous on $K$, compact, $\exists P_n \in {\mathbb R}[x]$ such that
$\textnormal{lim}_{n \rightarrow \infty} P_n(x)= f(x)$.
\\
\\
{\bf Lemma:} The Stone Weierstauss Theorem holds if 
$f, g \in {\overline {{\mathbb R}[x]}} \rightarrow max(f,g), min(f,g) \in {\overline {{\mathbb R}[x]}}$.
\begin{quote}
\emph{Proof of Lemma:} $\forall \alpha, \beta$, if $x_1 \ne x_2$, $\exists h \in {\overline {{\mathbb R}[x]}}$ such that
$h(x_1) = \alpha$ and $h(x_2) = \beta$.  To show this, pick $\phi \in {\mathbb R}[x]: \phi(x_1) \ne \phi(x_2)$ then put
$h(x) = \alpha + \beta {\frac {\phi(x) - \phi (x_1)} {\phi(x_2) - \phi (x_1)}}$.
Next we show that if $f$ is continuous on $S$ then, $\forall \epsilon > 0, \forall z \in {\overline {{\mathbb R}[x]}},
\exists g \in {\overline {{\mathbb R}[x]}}: f(z) - \epsilon < g(z) < f(z) + \epsilon$.  Let $h_{x,y}(z)$ be a function
with $h_{x,y}(x) = f(x)$ and $h_{x,y}(y) = f(y)$.  Such a function exists by the first part of this proof.
Let $U_x$ be a open neighborhood of $x$ in which $h_{x,y}(z) < f(z) + \epsilon$ which exists by continuity.
There is a finite subcover of $U_x$, $U_{x_1}, \ldots , U_{x_n}$.  Put $g = min(h_{x_1, y}, \ldots, h_{x_n, y})$.
Let $V_y$ be a open neighborhood of $y$ in which $f(z) - \epsilon < h_{x,y}(z)$, again we can find a finite
subcover and putting $g = max(h_{x,y_1}(z), \ldots, h_{x,y_m}(z))$, we get $f(z) < g(z) - \epsilon$.
$f(z) - \epsilon < g(z) < f(z) + \epsilon$, proving the lemma.
Note that $\sum_{i=0}^n {n \choose i} f({\frac {i}{n}}) x^i (1-x)^{n-i}$ is a good approximation of $f$.
\end{quote}
\begin{quote}
\emph{Proof of Stone Weierstrauss:} 
Since 
$max(f,g) = |f| + |g| + |f - g|$ 
and
$mix(f,g) = |f| + |g| - |f - g|$, it suffices to show $h(x) = |x| \in {\overline {{\mathbb R}[x]}}$.
Then $\forall \epsilon > 0, \exists P : |P(t) - |t|| < \epsilon$ and so $|P(f(x)) - |f(x)|| < \epsilon$.
Thus, $P(f(x)) \in {\overline {{\mathbb R}[x]}}$.
\end{quote}
{\bf Theorem:} Let ${\cal A}$ be an algebra of real continuous functions on a compact set $K$.   If
${\cal A}$ separates points and vanishes at no point then the uniform closure of ${\cal A}$ consists of all
real continuous functions.
\begin{quote}
\end{quote}
{\bf Taylor's Theorem:} $f(x)= \sum_{k=0}^n{\frac {f^{(k)}(a)} {k!}} (x-a)^k
+ {\frac {f^{(n+1)}(c)} {(n+1)!}}(x-a)^{n+1}$ for some $c: a<c<x$.
\begin{quote}
\emph{Proof:} Set $F(t)= \sum_{k=0}^n{\frac {f^{(k)}(t)} {k!}} (x-t)^k$ and let
$E_n(x)= f(x)-\sum_{k=0}^n{\frac {f^{(k)}(a)} {k!}} (x-a)^k$.  Note
$F(x)-F(a)=E_n (x)$ and
$F'(t)= {\frac {f^{(n+1)}(t)} {n!}}(x-t)^n$.  Put $G(t)= (x-t)^{n+1}$ and
$H(t)= G(t)[F(x)-F(a)]-F(t)[G[x]-G(a)]$.  $H(a)= H(x)$ so
$\exists c: a<c<x$ with $H'(c)=0$.  So
$E_n(x)=F(x)-F(a)= {\frac {F'(c)} {G'(c)}} [G(x)-G(a)]$.  Substituting gives
the desired result.
\\
\\
\emph{Another proof:}  $b= a+h$,
$f(b)= f(a)+ {\frac {(b-a)} {1!}} f^{(1)}(a)+ \ldots + 
{\frac {(b-a)^n} {n!}} f^{(n)}(a) + R_n(a)$.  Regard $b$ as constant and differentiate with respect to 
$a$.  By repeated application of the product rule, we get
$0= R_n'(a) + {\frac {(b-a)^{n}} {n!}} f^{(n+1)}(a)$.  Integrating (and switching limits), we get
$R_n(a)= \int^b_a {\frac {(b-t)^n} {n!}} f^{(n+1)}(t) dt$.  Applying the generalized mean value theorem
($p(x)>0 \rightarrow \int^b_a f(x)p(x) dx = f(\xi) \int^b_a p(x) dx, a \leq \xi \leq b$), we get
$R_n(a)= {\frac 1 {n!}} f^{(n+1)}(\xi) \int_b^a (b-t)^n dt ={\frac 1 {(n+1)!}} f^{(n+1)}(\xi) (b-a)^{n+1}$.
\\
\\
\emph{A third proof}:
Define $R_n(x,a)= \int_{a}^{x} f^{(n)}(t) {\frac {(x-t)^{n-1}} {(n-1)!}} dt$.
We proceed by induction.  We want to show $f(x) = f(a) + \sum_{i=1}^{n-1} {\frac {(x-a)^i} {i!}} f^{(i)}(a) + R_n(x, a)$.
For $n=1$, $f(x) - f(a) = \int_{a}^{x} f'(t) dt$ is just the FTOC.
For step $n+1$, we have from step $n$ that 
$f(x) -f(a) -\sum_{i=1}^{n} {\frac {(x-a)^i} {i!}} f^{(i)}(a) = \int_{a}^{x} f^{(n+1)}(t) {\frac {(x -t)^n} {n!}}dt$. 
Integrate by parts with
$u= f^{(n+1)}(t)$ and $v= -{\frac {(x -t)^{n+1}} {(n+1)!}}$. This gives
$f(x) - f(a) - \sum_{i=0}^{n+1} f^{(i)}(a) {\frac {(x-a)^i} {i!}} =
\int_{a}^{x} {\frac {(x-t)^{n+1}}{(n+1)!}}f^{(n+2)}(t) dt$ which is the result for $n+1$.
\end{quote}
{\bf Definition:}
$X$ separates if $\exists A, B, A \ne X, \emptyset, \exists B \ne X, \emptyset$ 
both open with $A \cup B = X$ and $A \cap B = \emptyset$.
$X$ is connected iff there is no separation.
Suppose $f: X \rightarrow Y$ is \emph{continuous.}  If $X$ is compact so is $f(X)$.  If
$X$ is connected, so is $f(X)$. If $X$ compact, \emph{connected}
set in ${\mathbb R}$ then $X=[a,b]$.
\\
\\
{\bf Some identities:}
$\int_{-\pi}^{\pi} cos(mx) cos(nx) dx = 
\int_{-\pi}^{\pi} sin(mx) sin(nx) dx=  \delta_{mn} \pi$.  
\emph{Bernoulli:} $\phi_n'(x)=\phi_{n-1}(x), \phi_0(x)=1, \int_0^1 \phi_n(x) dx = 1$.
$\Gamma (x) = \int_{0}^{\infty} u^{x-1} e^{-u} du$.
\\
\\
{\bf Optimization:}
$f$ has a global minimum if it is \emph{convex}.  $f$ is convex iff its \emph{Hessian} is
positive semi-definite.  An optimization problem is convex if the objective function and
the constraints are convex.  Convex optimization problems have global minimums.
\\
\\
{\bf Fixed Point Theorem:} 
Let $E$ be a complete metric space and $f: E \rightarrow E$.  Suppose
$\exists k<1: \forall p,q \in E, ||f(p)-f(q)|| \le k ||p-q||$.  Then there is a unique
$P \in E: f(P)=P$.  
\begin{quote}
\emph{Proof:} Let $p_{n+1}= f(p_n )$.
$||f(p_{n+1})-f(p_n)|| \le k ||p_n - p_{n-1}||\le k^n ||p_1-p_0||$.  This is a Cauchy
sequence and converges.  Set $p= lim_{n \rightarrow \infty} p_n$,
$f(p)=p$.  Uniqueness:  if $q$ is another such point:
$||f(p)-f(q)||= ||p-q|| \le k||p-q||$ so $||p-q||=0$.
\end{quote}
{\bf Simple Implicit Function Theorem:}  
Let $f$ be a real valued continuous function on an
open set $E \subset {\mathbb R}^2, (a,b) \in E$ with continuous partial
${\frac {\partial f} {\partial y}} (a,b) \ne 0$.  There are open sets $U,V$ with
$a \in U, b \in V$ and a continuous function $\varphi: U \rightarrow V$ such that
$f(x,\varphi(x))=0, x \in U$.  
\begin{quote}
\emph{Proof:}  
Define $F(x,y)= y-f(x,y) ({\frac {\partial f} {\partial y}})^{-1}$.  $F(a,b)=b,
{\frac {\partial F}{\partial y}} (a,b)=0$ and $F(x,y)=y$ iff $f(x,y)=0$.  Pick $r$
small enough so that in the ball $B_r(a,b):
|{\frac {\partial F}{\partial y}}|< {\frac 1 2}$.  Choose $k: 0<k<r$ then choose 
$h:0<h<{\sqrt {r^2-k^2}}$ such that
$|F(x,b)-b| < {\frac k 2}$ when $|x-a|<h$.
Put $U=(a-h,a+h), V=(b-k,b+k)$.
Fix $x \in U$ and $|y-b| \le k$ and suppose
$||(x,y)-(a,b)||^2<h^2+k^2<r^2$ and
$||(x,y')-(a,b)||^2<h^2+k^2<r^2$.  $\exists y'': |F(x,y)-F(x,y')| \le 
{\frac {\partial F} {\partial y}} (x, y'') |y-y'| \le
{\frac 1 2 } |y-y'|$ 
and $|F(x,y)-b| \le |F(x,y) - F(x,b)| + |F(x,b)-b| < k$.
Apply Fixed Point Theorem to get ${\overline y}= f(x, {\overline y})$.
This is unique.  Define $\varphi(x)= {\overline y}$.  A simple argument shows
$\varphi$ is continuous.
\end{quote}
{\bf Simple Inverse Function:} Let $g$ be a real valued function 
on an open set $E \subset {\mathbb R}$ and suppose $g'$ exists and is continuous in $E$
and $g'(b) \ne 0$.  There are open sets $U, V \subset {\mathbb R}$ with $b \in V: g_{|V}$
is 1-1 and $g^{-1}: U \rightarrow V$ is differentiable.  \emph{Proof:}  Put
$f(x,y)=x-g(y)$ and apply the implicit function theorem.
\\
\\
{\bf Existence of solution to ordinary differential equation:}  Let $f$ be a continuous
real valued function in an open set $E \subset {\mathbb R}^2$ containing $(a,b)$
and suppose $\exists M: |f(x,y)-f(x,z)|< M|y-z|, (x,y), (x,z) \in E$ then
$\exists h>0$ and $\varphi: (a-h, a+h) \rightarrow (b-M, b+M): \varphi'(x)= f(x,\varphi(x))$
on $(a-h, a+h)$ and $\varphi(a)=b$.  
\begin{quote}
Proof:  This is equivalent to
$\varphi(x)= \int_a^x f(t, \varphi(t)) dt +b$.  Suppose $\psi$ is a function and
define $F: \psi \mapsto \int_a^x f(t, \psi(t)) dt +b$.  $F$ maps the complete
metric space of functions on a closed interval of $E$ itself.  A fixed point in
this metric space would satisfy the theorem; we show such a fixed point exists.
Choose $N > |f(a,b)|, \exists r: ||(x,y)-(a,b)|| <r \rightarrow
|f(x,y)| < N$.  Choose $h>0: h < {\frac r {2N}}, h < {\frac 1 2}, hM < 1$ 
and consider the complete metric
space of continuous functions on $[a-h, a+h]$ denoted by
${\cal C}([a-h, a+h])$; define 
$R= \{ (x,y) \in E: |a-x| \le h, |y-b| \le Nh\}$ and
$B= \{ \psi: [a-h, a+h] \rightarrow [b-Nh, b+Nh] \}$, finally, Let
$B_{Nh}(b)$ be the ball in
${\cal C}([a-h, a+h])$ of functions within $Nh$ of the constant function $b$.
For $\psi, \omega \in B_{Nh}(b)$ note that $|\psi(x)-b| < Nh$ and $f(t,\psi(t))<N$
so $|F \psi (x)-b| < Nh$.
For $\psi, \omega \in B_{Nh}(b): |F \psi (x) - F \omega (x)| \le hM || \psi - \omega ||$.
This satisfies the conditions of the fixed point theorem and the fixed point
satisfies the conclusion of the theorem.
\end{quote}
{\bf Implicit Function Theorem:} Let 
$a \in E^m \subset {\mathbb R}^m$ and
$b \in E^n \subset {\mathbb R}^n$ with $(a,b) \subset E^{m+n}$, and open set.  Suppose
$f_1(a,b)= \ldots = f_n(a,b)=0$ and ${\frac {\partial f_i} {\partial y_j}}$
exist and are continuous in $E^{m+n}$ and 
$det({\frac {\partial f_i} {\partial y_j}}(a,b)) \ne 0$ then 
$\exists U^{open} \subset E^m, a \in U,
V^{open} \subset E^n, b \in V, \varphi: U \rightarrow V$ such that $f_i(x, \varphi(x))=0$
for $i= 1,2, \ldots, n$.  
\begin{quote}
\emph{Proof:}
Define $x={\vec x}= (x_1, \ldots, x_m)$,
$y={\vec y}= (y_1, \ldots, y_n)$ and $F= {\vec F}= (
F_1({\vec x}, {\vec y}) , \ldots,
F_n({\vec x}, {\vec y}))$.  Define $F_i(x,y)= y_i- \sum_j c_{ij} f_j (x,y)$ with each
partial continuous. (1) The $F_i$ are continuously differentiable; (2) $F_i(a,b)=b$;
(3) ${\frac {\partial F_i} {\partial y_j}}(a,b) = 0$; (4) $f_i(x,y)= 0$ iff
$F_i(x,y)= y_i$.  For 3 to hold $(c_{ij})$ must be the inverse of the Jacobian.  For
4 to hold, the determinant of the Jacobian must be $\ne 0$.  Choose $r>0$ such that
for $(x,y) \in B_r(a,b) \subset E^{m+n}$, 
$|{\frac {\partial F_i} {\partial y_j}}| < {\frac 1 {2n^2}}$ and
$det({\frac {\partial F_i} {\partial y_j}}) \ne 0$.  Choose $k: 0 < k < r$ and
choose $h$ so that $0 < h < {\sqrt {r^2 - k^2}}$ and
$||F(x,b) - b|| < {\frac k 2}$ if $||x-a|| < h$.  Fix $x \in U$ with
$||(x,y)-(a,b)||<r$.  If $y' \in E^n , ||y'-b|| \le k, \exists y'':
F(x,y)-F(x,y') = (y-y') \cdot 
({\frac {\partial F_1(x,y'')} {\partial y_1}}, \ldots , 
{\frac {\partial F_n(x,y'')} {\partial y_n}}) \le
{\frac 1 {2n^2}}(|y_1-y_1'| + \ldots + |y_n-y_n'|) \le {\frac 1 {2n}} ||y-y'||$.
So $||F(x,y)-F(x,y')||<k$ and the fixed point theorem applies.
\end{quote}
{\bf Extended Inverse Function Theorem:} $f_i(x,y)= x_i - g_i(y), a= g(b)$.  Same deal.
\\
\\
{\bf Inverse Function Theorem:}
Suppose $f: {\mathbb R}^n \rightarrow {\mathbb R}^n$ is continuously differentiable
and $|det(f'(a)| \ne 0$.  
$\exists V^{open}, W^{open}, f^{-1}, a \in V, f(a) \in W $ with
$f^{-1}: W \rightarrow V$ and $f^{-1}(f(x)=x$.  Further 
$f'^{-1}(y)= {\frac 1 {f'(f^{-1}(y))}}$.
\\
Notes:  Let $\lambda =D(f(a))$.  May assume $\lambda= I$.  Can show
$|x_1 - x_2 | \leq |f(x_1 ) - f(x_2 )|$.
\\
\\
{\bf Implicit Function Theorem:}  If $f: {\mathbb R}^n \times {\mathbb R}^m  
\rightarrow {\mathbb R}^m$ is continuously
differentiable in an open set containing 
$(a,b), f(a,b)=0$ with $M= (D_{n+j}(f^i (a)))$ with
$1 \leq i,j \leq m$.  If $det(M) \ne 0, \exists A^{open} \subseteq {\mathbb R}^n$ 
and $B^{open} \subseteq {\mathbb R}^m, a \in A, b \in B: \forall x \in A$ 
there is a unique $g(x) \in B, f(x,g(x))=0$.
Further, $g$ is differentiable.
\\
Notes:  Look at $F(x,y)=(x,f(x,y))$ and apply Inverse Function Theorem.
\\
\\
{\bf Partitions of unity:}
$A^{open} \subseteq {\mathbb R}^n$ and ${\cal O}$ and open cover of $A$.
$\exists \Phi \in {\mathbb C}^{\infty}$ such that $\forall \varphi \in \Phi$: 
(1) $0 \leq \varphi(x) \leq 1$ and $\forall x \in A$,
(2) $\forall x, \varphi(x) = 0$ for all but finitely many $\varphi \in \Phi$,
(3) $\sum_{\varphi \in \Phi} \varphi(x) =1$.
(4) $\forall \varphi \in \Phi, \exists U^{open} \in {\cal O}: \phi(x) = 0$ for $x \notin 
{\overline U}$
where ${\overline U}$ is some closed subset of $U$.
\\
\\
{\bf Direct proof of inverse function theorem:}
Suppose $f$ is a ${\cal C}'$ mapping
$f: E \rightarrow {\mathbb R}^n$, $a \in E^{open} \subseteq {\mathbb R}^n$ with 
$f'(a)$ invertible
and $f(a)=b$, then (a) $\exists U^{open}, V^{open} \subseteq {\mathbb R}^n :
a \in U, b \in V$ such that $f$ is 1-1 on $U$; $f(U)=V$. (b) If $g= f^{-1}$ then
$g \in {\cal C}'(V)$.\\
\emph{Proof of a:}
Put $f'(a)=A$ and choose $\lambda: 2 \lambda ||A^{-1}||=1$, 
set $U= B_{\lambda}(a) \subseteq E$: $||f'(x)-A|| < \lambda, \forall x \in U$.  Set
$\varphi_y(x)= x+ A^{-1} (y-f(x)), \forall y \in {\mathbb R}^n$.
$||\varphi_{y}'(x) || = || A^{-1} (A-f'(x)) || < {\frac 1 2}$.
$|| \varphi_y(x_1)- \varphi_y(x_2)|| < {\frac 1 2}, \forall x_1, x_2 \in U$ [Equation 1]
by the mean value
theorem.  $\varphi_y$ is a contraction map so it has a unique fixed point $x: y=f(x)$.
Put $V=f(U)$ and suppose $y_0 \in V$, there is a $x_0 \in U: y_0=f(x_0)$.  Pick
$r>0: {\overline {B_r(x_0)}} \subseteq U$.
Fix $y: |y-y_0|<\lambda r$.  For 
$x \in {\overline {B_r(x_0)}}$,
$| \varphi(x_0) - x_0 | \le 
|\varphi(x)-\varphi(x_0)| +
|\varphi(x_0)-x_0|< {\frac 1 2} |x-x_0| + {\frac r 2} \le r$ so $\varphi(x) \in
{\overline {B_r(x_0)}}$ and again
$\varphi_y$ is a contraction map.  Its fixed point $x$ satisfies
$f(x)=y, y \in 
{\overline {B_r(x_0)}} 
\subseteq f(U)=V$, so $V$ is open.
\\
\emph{Proof of b:}
Pick $y \in V$, $y+k \in V, \exists x, x+h \in U:
y=f(x), y+k= f(x + h)$.  Now $\varphi(x+h) - \varphi(x) = h + A^{-1}(f(x+h)-f(x)) =
h- A^{-1}(f(x+h)-f(x))= h- A^{-1}k \le {\frac 1 2} h$ by equation 1, so
$||A^{-1}k|| \ge {\frac {||h|||} 2}$ and 
$ ||h|| \le 2 ||A^{-1} k||= \lambda^{-1} ||k||$.  $f'(x)$ has an inverse $T$ and
$g(y+k)-g(y)-Tk=h-Tk= -T[f(x+h)-f(x) -f'(x)h]$ and
${\frac {||g(y+k)-g(y)-Tk||} {||k||}} ={\frac {||T||} {\lambda}} 
{\frac {||f(x+h)-f(x) -f'(x)h||} {||h||}}$. Now $h \rightarrow 0$ as 
$k \rightarrow 0$.  Since the right hand side goes to $0$, the left hand side goes to
$0$ and we get $g'(y)= T$.
\\
\\
{\bf Fubini's Theorem:}
$\int \int_{I^2} f(x,y) dy dx = \int_0^1 (\int_0^1 f(x,y) dy) dx$.  In
a simply connected region of the plane, $S$ for $a \leq x \leq b$ bounded by
$b_1(x) \leq y \leq b_2(x)$,
$\int \int_{S} f(x,y) dy dx = \int_a^b (\int_{b_1(x)}^{b_2(x)} f(x,y) dy) dx$.
\begin{quote}
\emph{Proof:}  Partition the region in steps of $\Delta x$ and $\Delta y$.  Summing over
rectangles in the $y$ direction moving and then moving in the positive $x$ direction gives the result.
\end{quote}
{\bf Change of variables:}
Let $A \subseteq {\mathbb R}^n$ be an open set, $g:A \rightarrow R$ 
continuously differentiable and
$det(g'(x)) \ne 0, \forall x \in A$.  If $f: g(A) \rightarrow R$ is integrable
then $\int_{g(A)} f = \int_A f \circ g |\det(g')|$.
\begin{quote}
\emph{Proof:} Use the following: If $A$ is an $n \times n$ matrix. $det(A)$ is the volume of the 
image of the unit $n$-cube under $A$.
\end{quote}
Let ${\cal T}^k (V)= \{ T:V \rightarrow {\mathbb R} \}, V \subseteq 
{\mathbb R}^n $
where $\forall i$: 
$T(v_1, ..., v_{i-1}, u+w, v_{i+1},...,v_k)= T(v_1, ..., v_{i-1}, u, v_{i+1},...,v_k)+
T(v_1, ..., v_{i-1}, w, v_{i+1},...,v_k )$ and
$T(v_1, ..., v_{i-1}, au, v_{i+1},...,v_k)= aT(v_1, ..., v_{i-1}, u, v_{i+1},...,v_k)$.
${\cal T}^n(V)$ are called the $n-$tensors $V$.
If $f: V \rightarrow W$ with $V, W \subseteq {\mathbb R}^n$ then 
$f^*: {\cal T}^n (W) \rightarrow {\cal T}^n (V)$ by 
$f^* (T( v_1 , ... , v_n ))=
T(f(v_1) , ... , f(v_n ))$.
If $T \in {\cal T}^k, S \in {\cal T}^s$ define
$T \otimes S = T(x_1) S(x_2 )$.  ${\cal T}^1(V)$ is just the dual space $V^*$.
If $e_1 , ... , e_n$ is a basis for $V$ and
$\varphi_j \in V^*$ such that $\varphi_j (e_i)= \delta_{ij}$ then
the set of all $k-fold$ tensor products
$ \varphi_{i_1} \otimes  \varphi_{i_2}\otimes ... \otimes \varphi_{i_k}$ 
is a basis ${\cal T}^k(V)$
which thus has dimension $n^k$.  \\
\\
{\bf Definition:}
An \emph{alternating form} is a multilinear function,
$\Lambda^k(V)= \{T \in {\cal T}^k(V)\}$ such that $T(...v...w...)= -T(...w...v...)$.
$\forall T \in {\cal T}^n(V), Alt(T)= {\frac 1 {k!}} \sum_{\sigma} sgn(\sigma ) T(
v_{\sigma (1)},..., v_{\sigma (n))} 
\in \Lambda^k(V)$. If
$\omega \in \Lambda^k(V)$, $Alt( \omega) = \omega$.
If $\omega, \eta \in \Lambda^k , \Lambda^l$, $\omega \wedge \eta =
{\frac {(l+k)!} {k! l!}} Alt( \omega \otimes \eta )$. $\wedge$ is multilinear and
$\omega \wedge \eta= (-1)^{kl} \eta \wedge \omega$; $f^*(\omega \wedge \eta) =
f^*(\omega) \wedge f^*(\eta)$. 
$
(\omega \wedge \eta ) \wedge \theta =
\omega \wedge (\eta \wedge \theta)=
{\frac {(k+l+m)} {k!l!m!}} Alt(\omega \otimes \eta \otimes \theta)$.
If $\omega = \sum  w_{{i_1} , ... {i_k}} dx^{i_1} \wedge ... \wedge x^{i_k}$ then
$d \omega = \sum dw_{{i_1}  ... {i_k}} \wedge dx^{i_1} \wedge ... \wedge x^{i_k}$.
$dim(\phi_{i_1} \wedge ... \wedge \phi_{i_k}) = {n \choose k}$.
orientation: $[e_1 , ... , e_n]$.
\emph{Volume elements:}
$w_i= \sum_j a_{ij} v_j$ then $\omega (w_1 ,..., w_n)= det(a_{ij})
\omega (v_1 , ... , v_n )$ for $\omega \in \Lambda^k$.
\\
\\
{\bf Forms:} Let $p, v \in {\mathbb R}^n$, define the tangent space of ${\mathbb R}^n$ 
at $p$, ${{\mathbb R}^n}_p$, as the $(p,v)$ with 
$(p,v)+(p,w)= (p, v+w)$ and $(p,av)= a(p, v)$.
\\
\\
{\bf Vector field:}
$F(p)= F^1 (p) (e_1)p + ... + F^n (p) (e_n)p$ with the usual rules $(F+G)(p)= F(p)+G(p)$
$(f \cdot g)(p)= f(p) \cdot g(p)$. $\nabla= \sum D_i \cdot e_i$.
\\
\\
{\bf Differentials:}
$\omega(p) \in \Lambda^k ({{\mathbb R}^n}_p)$:  If $\varphi_i(p)$ is the dual basis for
$(e_1)_p , (e_2)_p , ..., (e_n)_p$ then
$\omega (p) = \sum
\omega_{{i_1} , ... {i_k}} \varphi^{i_1} \wedge ... \wedge \varphi^{i_k}$ is
a differential form and $df(p)(v_p)=Df(p) (v)$. $df= \sum_i^n D_i f dx^i$.
\\
\\
{\bf Results on forms:} If 
$f: {\mathbb R}^n \rightarrow {\mathbb R}^m$,
$f_*: {{\mathbb R}^n}_p \rightarrow {{\mathbb R}^m}_p$ by
$f_* (v_p)= (Df(p)(v))_{f(p)}$.  
Thus $f_*: \Lambda^k({{\mathbb R}^m}_{f(p)}) \rightarrow \Lambda^k({{\mathbb R}^n}_p)$.  So if
$\omega$ is a $k-$form on ${\mathbb R}^m$, $f^* \omega (p) = f^*(\omega(p))$ is a $k-$form on ${\mathbb R}^n$.
$f^* (dx^i) = \sum_j D_j f^i \cdot dx^j$, 
$f^* (\omega_1 + \omega_2 )= f^* (\omega_1 ) + f^*(\omega_2 )$, 
$f^* (g \cdot \omega)= g \circ f f^* \omega$ and
$f^* (\omega + \eta )= f^* \omega + f^* \eta$.
If $f: {\mathbb R}^n \rightarrow R$, $Df(p) \in \Lambda^1 ({\mathbb R}^n)$.
$df(p) (v_p )= Df(p)(v)$.  $f_* (v_p )= (Df(p)(v))_{f(p)}$.
$f: {\mathbb R}^n \rightarrow {\mathbb R}^m$, $f_*: {{\mathbb R}^n}_p \rightarrow {{\mathbb R}^m}_{f(p)}$.
$f_* : \Lambda^k ({{\mathbb R}^m}_{f(p)}) \rightarrow \Lambda^k({{\mathbb R}^n}_p )$.
$f^*(dx^i) = \sum_{j=1}^n D_j f^i dx^j$.  $f^* (g \circ \omega ) = g \circ f \circ 
f^* \omega$. \emph{Example:} Suppose
$\omega= f_1 dx_1 + f_2 dx_2 + f_3 dx_3 $ then
$d\omega= (\nabla f_1) \cdot (dx_1, dx_2, dx_3) \wedge dx_1 +
(\nabla \cdot f_2) (dx_1, dx_2, dx_3) \wedge dx_2 +
(\nabla \cdot f_3) (dx_1, dx_2, dx_3) \wedge dx_3$.
\\
\\
{\bf Definitions:}
$\omega$ is a \emph{closed form} if $d \omega = 0$.
$\omega$ is an \emph{exact form} if $\exists \eta: d \eta = \omega$.
Note that $d^2 \omega = 0$.
\\
\\
{\bf Poincare:}  If $A^{open} \subseteq {\mathbb R}^n$ is a star 
shaped region then every closed form in $A$ is exact.
$\partial I^n= \sum_{i=1}^n \sum_{\alpha = 0,1} (-1)^{i+ \alpha} {I^n}_{(i, \alpha)}$ where
${I^n}_{(i, \alpha)}= I^n(x^1 , ... , , x^{i-1}, \alpha , x^{i+1} , ... x^n )$.
Note that $\partial^2 I^n = 0$.
If $A^{open} \subseteq {\mathbb R}^n$ and $g: A \rightarrow {\mathbb R}^p$ 
is differentiable and $g'(x)$ has
rank $p$ whenever $g(x)= 0$ then $g^{-1}(0)$ is an $n-p$ dimensional manifold.
An $n$-dimensional differentiable manifold is called \emph{orientable}
if it has a differential form $\omega$ 
of degree $n$ which is nonzero at every point on the manifold.
\\
\\
{\bf Lagrange Multipliers:} Maximize 
$F({\vec x})$ subject to
$\phi_1({\vec x})=0, \phi_2({\vec x})=0, \ldots , \phi_m({\vec x})=0$;
form 
$G({\vec x})= F({\vec x})+ \lambda_1 \phi_1({\vec x}) + \lambda_2 \phi_2({\vec x}) + 
\ldots + \lambda_m \phi_m({\vec x})$ and  solve
${\frac {\partial G} {\partial x_j}}=0$.  Motivation: all curves, $s(t)$ that satisfy constraints
must satisfy $\nabla \phi_j(s(t)) \cdot \dot{s}(t) = 0$.  Similarly, if $s(t)$ is a curve,
${\frac {df(s(t))} {dt}} = 0 = \nabla f(s(t)) \cdot \dot{s}(t)$.
\\
\\
{\bf Vectors:} 
(a) If $\nabla \times f = 0$, $f= \nabla g$.
(b) If $\nabla \cdot f = 0$, $f= \nabla \times g$.
\begin{quote}
\emph{Proof of a:}  Put $g(x,y,z)= \int_{x_0}^x f_1(x,y,z)$,
$\partial_x g= f_1$ by fundamental theorem of calculus.
$\partial_y g= \partial_y \int_{x_0}^x f_1(x,y,z)=
\int_{x_0}^x \partial_y f_1(x,y,z)= \int_{x_0}^x \partial_x f_2(x,y,z)= f_2$, etc.
\\
\emph{Proof of b:}  
Put $g_1(x,y,z)= 0$,
$g_2(x,y,z)= \int_{x_0}^x f_3(t,y,z) dt - \int_{z_0}^z f_1(x_0, y, u) du$,
$g_3(x,y,z)= - \int_{x_0}^x f_2(t,y,z) dt$.  Using the fact that $\nabla \cdot (f_1, f_2, f_3)=0$,
we get $\nabla \times (g_1, g_2, g_3) = (f_1, f_2, f_3)$.
\end{quote}
{\bf Change of variables:} 
Let ${\vec x}= (x_1 , x_2 , \ldots , x_n)$.
Suppose 
${\cal R} \subseteq {\mathbb R}^n$
${\cal R}' \subseteq {\mathbb R}^n$ and the bijection
$f: {\cal R} \rightarrow {\cal R}'$ is continuously differentiable
then $\int_{{\cal R}'} F({\vec x}) d {\vec x}
= \int_{{\cal R}} F(f({\vec u})) |J_f({\vec u})| d {\vec u}$ where
$J_f({\vec u}) = | det(f')|$.
\\
\\
{\bf Singular cube and boundaries:} Given a singular cube $I^n(x_1 , \ldots , x_n)$, the boundary of $I^n$
is $\partial I^n = \sum_{j=1}^n \sum_{\alpha = 0, 1} I^n_{[j, \alpha]}$ where 
$^n_{[j, \alpha]} = I^n(x_1, \ldots, x_{j-1}, \alpha , x_{j}, \ldots , x_{n-1})$.
\\
\\
{\bf Green:} 
If $C$ surrounds ${\cal R}$, a simply connected
region of the plane then $\int_C P dx + Q dy= \int_{\cal R}
({\frac {\partial Q} {\partial x}} -
{\frac {\partial P} {\partial y}}) dx dy $.  
\begin{quote}
\emph{Proof:} Just apply Fubini with bounding curves.
\end{quote}
{\bf Gauss:} If ${\cal S}$ is a surface enclosing
a convex region ${\cal V}$ and ${\vec F}$ is continuously differentiable then
$\int_{\cal V} \nabla \cdot {\vec F} ({\vec x}) d{\vec x}
= \int_{\vec S} {\vec F}({\vec x}) \cdot dS$.
\begin{quote}
\emph{Proof:} Apply Fubini and the Fundamental Theorem of Calculus.
\end{quote}
{\bf Stokes:} If ${\cal S}$ with boundary
${\cal C}$ and ${\vec F}$ is continuously differentiable then
$\int_{\cal S} \nabla \times {\vec F} ({\vec x}) \cdot dS
= \int_{\vec C} {\vec F}({\vec x}) \cdot d{\vec l}$.
\begin{quote}
\emph{Proof:} Apply Fubini and the Fundamental Theorem of Calculus.
\end{quote}
{\bf Modern formulation of Stokes:} If $M$ is a compact oriented $k-$dimensional manifold with boundary
and $\omega$ is a $k-1$ form on $M$ then $\int_c d \omega = \int_{\partial c} \omega$.
\\
\\
{\bf Fourier:}
$F(x)= {\frac 1 {\sqrt {2 \pi}}} \int_{-\infty}^{\infty} f(u) e^{i u x} du$ and
$f(u)= {\frac 1 {\sqrt {2 \pi}}} \int_{-\infty}^{\infty} F(x) e^{-i u x} dx$.
\begin{quote}
{\bf Proof:} First show that if $\psi(t)$ is bounded and continuous on
$(a,b)$ then $\textnormal{lim}_{A \rightarrow \infty} \int^b_a \psi(t) sin(At) dt = 0$.
Look at $I_A= {\frac 1 {\pi}} \int^A_0 d \tau \int^{\infty}_{-\infty} dt f(t) cos( \tau (t-x))$.
Also note that $\int^{\infty}_0 {\frac {sin(At)} {t}} dt = {\frac {\pi} {2}}$
\end{quote}
{\bf Fourier:} Let $f(x)$ be defined for $-L \leq x \leq L$ with $f(x+2L)=f(x)$ then
$f(x)= {\frac {a_0} 2} + \sum_{n=1}^{\infty} (a_n cos({\frac {n \pi x} L}) +
b_n sin({\frac {n \pi x} L} ))$ with
$a_n= \int_{-L}^L f(x) cos({\frac {n \pi x} L}) dx$ and
$b_n= \int_{-L}^L f(x) sin({\frac {n \pi x} L}) dx$.  Parseval: 
$\int_{-L}^L f(x)^2= {\frac {{a_0}^2} 2} + \sum_{n=1}^{\infty} {a_n}^2 + {b_n}^2$. If
$F(x)= {\frac 1 {\sqrt {2 \pi}}} \int_{-\infty}^{\infty} f(u) e^{i u x} du$,
$\int_{-\infty}^{\infty} F(\alpha) G(\alpha) e^{i \alpha u} du=
\int_{-\infty}^{\infty} f(u) g(x-u) du $.
\\
\\
{\bf Calculus of variations:}  Let $I= \int_{x_1}^{x_2} L(x, y, y') dx$ and $f(x)$ be the
function that minimizes $I$ ($\delta I = 0$), then
$ -{\frac {d} {dx}} {\frac {\partial L} {\partial y'}} +
{\frac {\partial L} {\partial y}}= 0 $.
\begin{quote}
\emph{Proof:}
Let $\eta(x)$ be a small functional variation with $\eta(x_1)=\eta(x_2)=0$.
$\delta I= \int_{x_1}^{x_2} L(x, y+ \eta, y' + \eta') dx -
\int_{x_1}^{x_2} L(x, y, y') dx$.
$\delta I= \int_{x_1}^{x_2} ({\frac {\partial L(x, y, y' + \eta')}{\partial y}} \eta(x)+
{\frac {\partial L(x, y, y')}{\partial y'}} \eta(x)') dx$.  Integrating by parts and using
$\eta(x_1)=\eta(x_2)=0$,
$\delta I= \int_{x_1}^{x_2} 
({\frac {\partial L(x, y, y')}{\partial y}} -
{\frac {d} {dx}}{\frac {\partial L(x, y, y')}{\partial y'}}) \eta(x)
dx$.   Since $\delta I= 0$ and $\eta$ was arbitrary,
${\frac {\partial L(x, y, y')}{\partial y}} -
{\frac {d} {dx}}{\frac {\partial L(x, y, y')}{\partial y'}} = 0$.  This is the 
Euler-Lagrange equation.  In physics, $L= KE-PE$.
\end{quote}
\subsection{Complex Analysis}
{\bf Stereographic projection:}
Let $S= \{ (x_1 , x_2 , x_3 ) \in {\mathbb R}^3: x_1^2 + x_2^2 + x_3^2 = 1 \}$.
Consider the bijective correspondence $S - \{(0,0,1)\} \leftrightarrow {\mathbb C}$ given by
$(x_1, x_2, x_3) \mapsto {\frac {x_1 + i x_2} {1-x_3}}$.  $S$ is called the \emph{Riemann sphere} and
$(0,0,1) \mapsto \infty$.  
$x_1= {\frac {z + {\overline z}}{1+|z|^2}}$,
$x_3= {\frac {z - {\overline z}}{1+|z|^2}}$
\\
\\
{\bf Theorem:}  If all zeros of $P \in {\mathbb C}[z]$ lie in a half plane so do the zeros of $P'(z)$.
\\
\\
{\bf Theorem:}  If $R(z)= {\frac {a_0 + a_1 z + a_2 z^2 + \ldots + a_n z^n}
{b_0 + b_1 z + b_2 z^2 + \ldots + b_m z^m}
}$, the number of poles is $max(m,n)$ and so is the number of zeros; the common value is called the
order of $R$.
\\
\\
{\bf Theorem:}  If $f(z)= a_0 + a_1 z + a_2 z^2 + \ldots + a_n z^n + \ldots $, the \emph{radius of convergence} is
$R$.  The function is analytic if $|Z| <R$ and
${\frac 1 R}= \textnormal{lim sup}_{n \rightarrow \infty} |a_n|^{1/n}$.
\\
\\
{\bf Theorem:}  If $a_0 + a_1  + a_2  + \ldots + a_n + \ldots $ converges then
$f(z)= a_0 + a_1 z + a_2 z^2 + \ldots + a_n z^n + \ldots $ tends to $f(1)$ as $z \rightarrow 1$ and
${\frac {|1-z|}{1-|z|}}$ remains unbounded.
\\
\\
{\bf Theorem:}  A cross-ratio is real iff all four points lie on a circle or a straight line.
\\
\\
{\bf Definition:} A function is \emph{analytic} in $\Omega$ if it is differentiable.
A function that is analytic on all of ${\mathbb C}$ is called \emph{entire}.  A function that
is analytic on all of ${\mathbb C}$ except at a finite number of poles is called \emph{meromorphic}.
Over ${\mathbb C}$, the unimodular transformations are of the form $z \mapsto {\frac {az+b} {cz+d}}$.
$log(w)= log(|w|)+iarg(w)$.
\\
\\
{\bf Definition:} $Im({\frac {z-a} {b}})<0$ is a \emph{half-plane}.  A set is connected if
it cannot be be written as a union of non-empty disjoint open sets.  A space is \emph{Hausdorff} if
$\forall x, y$ there are open subsets $O_1, O_2$ such that
$x \in O_1, y \notin O_1$ and
$y \in O_2, x \notin O_2$.
A \emph{region} is a connected open set.
\\
\\
{\bf Theorem:}
If $f(x+iy)= u(x,y)+ i v(x,y)$ is analytic in a region ${\cal R}$ then
${\frac {\partial u} {\partial x}}= {\frac {\partial v} {\partial y}}$
and ${\frac {\partial u} {\partial y}}= -{\frac {\partial v} {\partial x}}$.
\begin{quote}
\emph{Proof:}
$f'(z) = lim_{\Delta x \rightarrow 0} 
{\frac {u(x+\Delta x, y)-u(x,y)}{\Delta x}} + i {\frac {v(x+\Delta x, y)-v(x,y)}{\Delta x}}=
{\frac {\partial u} {\partial x}} + i {\frac {\partial v} {\partial x}}$.  Similarly,
$f'(z) = lim_{\Delta y \rightarrow 0} 
{\frac {u(x, y + \Delta y)-u(x,y)}{i \Delta y}} + 
i {\frac {v(x, y+ \Delta y)-v(x,y)}{i \Delta y}}=
-i {\frac {\partial u} {\partial y}} + {\frac {\partial v} {\partial y}}$. 
\end{quote}
{\bf Cauchy's Theorem:} If $f(z)$ is analytic in a region ${\cal R}$ and
its boundary is ${\cal C}$ then $\int_{\cal C} f(z) dz = 0$.
\begin{quote}
\emph{Proof:}
Let $f(x+yi)= u(x,y)+ i v(x,y)$.  $
\int_{\cal C} (u+vi)(dx+idy)=
\int_{\cal C} (udx-vdy) + i(v dx + u dy)$.  By Green's theorem,
$\int_{\cal C} (udx-vdy) + i(v dx + u dy)= \int \int_{\cal R}  [
({\frac {\partial (-v)} {\partial x}} - {\frac {\partial u} {\partial y}}) +
i({\frac {\partial (u)} {\partial x}} - {\frac {\partial v} {\partial y}}) ]
dx dy$.  Each parenthesized term is $0$ by the previous theorem.
\end{quote}
{\bf Theorem:}  
The line integral $\int_{\gamma} p \thinspace dx + q \thinspace dy$ in $\Omega$ depends only on the
endpoints iff 
$\exists U: p= {\frac {\partial U}{\partial x}}, q= {\frac {\partial U}{\partial y}}$.
\begin{quote}
\emph{Proof:}
$\leftarrow$: $\int_{\gamma(t), a \leq t \leq b} p \cdot dx + q \cdot dy =
\int_a^b {\frac {dU} {dt}} dt = U(\gamma(b)) - U(\gamma(a))$.
$\rightarrow$: Define $U(x,y) = \int_{(\alpha, \beta)}^{(x, y)} p \cdot dx + q \cdot dy$,
which is well defined since the integral only depends on endpoints.
$p = {\frac {\partial U} {\partial x}}$ and 
$q = {\frac {\partial U} {\partial y}}$.
\end{quote}
{\bf Theorem:}  
If $f$ is analytic in and on $R- \{ a_1 , \ldots , a_k \}$, where
$\textnormal{lim}_{z \rightarrow a_i} f(z)(z-z_i)= 0$ then $\int_{\partial R} f(z) = 0$
\begin{quote}
\end{quote}
{\bf Definition:} 
If $\gamma$ is a closed curve containing $a$, define  $n(\gamma, a)= {\frac 1 {2 \pi i}} 
\int_{\gamma} {\frac {dz}{z-a}}$. 
\\
\\
{\bf Theorem:}  
If $f$ is analytic 
and $\gamma$ is a closed curve containing $a$, $f(a)= {\frac 1 {2 \pi i n(\gamma, a)}} \int_{\gamma}
{\frac {f(z)} {z-a}} dz$.
\begin{quote}
\emph{Proof:} Put $z = a + re^{i \theta}$ and perform the integrations with $r$ small.
Now apply Cauchy's theorem in the annular region when $r$ is large.
\end{quote}
{\bf Theorem:}  
If $\varphi$ is continuous on $\gamma$ then $F_n(z)=
\int_{\gamma} {\frac {\varphi(w)} {(w-z)^n}} dw$ is analytic and $F_n'(z)= n F_{n+1}(z)$.
\begin{quote}
\end{quote}
{\bf Theorem:}
If $f(z)$ is analytic inside and on a circle ${\cal C}$ of
radius $r$ and center at $z=a$ then $f(a)= {\frac 1 {2 \pi}} \int_0^{2 \pi} 
f(a+ r e^{i \theta}) d \theta$.
\begin{quote}
\emph{Proof:}
Because $f$ is analytic,
$ {\frac 1 {2 \pi}} \int_0^{2 \pi} f(a+r_1 e^{i \theta}) d \theta
= {\frac 1 {2 \pi}} \int_0^{2 \pi} f(a+r_2 e^{i \theta}) d \theta$
if $r_1, r_2>0$; so by continuity,
$ {\frac 1 {2 \pi}} \int_0^{2 \pi} f(a+r_1 e^{i \theta}) d \theta=
lim_{r \rightarrow 0} {\frac 1 {2 \pi}} \int_0^{2 \pi} f(a+r_1 e^{i \theta}) d \theta =
f(a) $.
\end{quote}
{\bf Cauchy Integral Formula:}
If $f(z)$ is analytic inside and on a closed curve ${\cal C}$ and $a$ is any
point inside ${\cal C}$ 
then  $f^{(n)}(a)= {\frac 1 {2 \pi i}} \int_{\cal C} {\frac {f(z)} {(z-a)^{n+1}}} dz$.
\begin{quote}
\emph{Proof:}
By induction.  For $n=0$, put $z= a+r e^{i \theta}$ then
${\frac 1 {2 \pi i}} \int_{\cal C} {\frac {f(z)} {(z-a)}} dz=
{\frac 1 {2 \pi i}} \int_{0}^{2\pi} i f(a+re^{i \theta}) d \theta = f(a)$.  Now
by the $n=0$ result, ${\frac {g(a+h)-g(a)} {h}}= 
{\frac 1 {2 \pi i h}} \int_{\cal C}
({\frac {g(z)} {(z-a-h)}}- {\frac {g(z)} {(z-a)}}) dz= 
{\frac 1 {2 \pi i}} \int_{\cal C} {\frac {g(z)} {(z-a)(z-a-h)}} dz$ provided ${\cal C}$
encloses both $a$ and $a+h$.  Taking the limit as $h \rightarrow 0$, we get
$g'(a)= {\frac 1 {2 \pi i}} \int_{\cal C} {\frac {g(z)} {(z-a)^2}} dz$ 
and the result follows by induction.
\end{quote}
{\bf Morrera's Theorem:}
If $f(z)$ is continuous in a simply connected region ${\cal R}$ and
$\int_{\cal C} f(z) dz = 0$ around every simple closed curve
${\cal C}$ in ${\cal R}$, then $f(z)$ is analytic in ${\cal R}$.
\begin{quote}
\emph{Proof:}
By contunuity, the integral exists and by Cauchy's integral formula, the derivative exists.
\end{quote}
{\bf Theorem:}
If $f(z)$ is analytic inside and on a circle ${\cal C}$ of
radius $r$ and center at $z=a$ then $|f^{(n)}(a)| \leq {\frac {M} {r^n}}$ where
$|f(z)| \leq M$ on ${\cal C}$ in ${\cal R}$.  If an analytic function is bounded in the
plane it is constant.  If $a_n$ is the coefficient of $z^n$ in the Taylor expansion of
$f(z)$ about $a$, and $f$ is bounded as above, 
$|a_n|= |{\frac {f^{(n)}(a)} {n!}}| \leq {\frac {M n!} {r^n}}$.
\begin{quote}
\emph{Proof:}
Let ${\cal C}(r)$ be a circle of radius $r$ then by Cauchy's integral formula,
$f^{(n)}(a)= 
{\frac 1 {2 \pi i}} \int_{{\cal C}(r)} {\frac {f(z)} {(z-a)^{n+1}}} dz=
{\frac 1 {2 \pi i}} \int_{0}^{2 \pi} 
{\frac {f(a+re^{i \theta})} {(re^{i \theta})^{n+1}}} r e^{i \theta} d \theta$.
So $|f^{(n)}(a)|= {\frac {|M|} {r^n}}$.  The two subsequent statements follow easily.
\end{quote}
{\bf Theorem:}
If $f(z)$ is analytic inside and on a closed curve ${\cal C}$ except at
a finite number of pole
then  ${\frac 1 {2 \pi i}} \int_{\cal C} {\frac {f'(z)} {f(z)}} =
N-P$ where $N$ and $P$ are, respectively, the number of zeros and poles of
$f(z)$ inside ${\cal C}$.
\begin{quote}
\emph{Proof:}
Let $f(z)= p(z) g(z)$ so $f'(z)= p'(z)g(z)+p(z)g'(z)$.  Thus
$\int_{\cal C} {\frac {f'(z)} {f(z)}} dz= 
\int_{\cal C} {\frac {p'(z)} {p(z)}} + {\frac {g'(z)} {g(z)}} dz $.  So by induction,
it suffices to consider $p(z)= (z-a)$ and $p(z)= (z-a)^{-1}$.  In the first case, 
setting $z=re^{i \theta}$
$\int_{\cal C} {\frac {p'(z)} {p(z)}} dz= 
\int_{\cal C} {\frac {1} {(z-a)}} dz= {\frac 1 {2 \pi i}} \int_0^{2 \pi} i d \theta = 1$
and in the second case, again setting $z=re^{i \theta}$
$\int_{\cal C} {\frac {p'(z)} {p(z)}} dz= 
\int_{\cal C} {\frac {-1} {(z-a)}} dz= {\frac {-1} {2 \pi i}} \int_0^{2 \pi} i d \theta = -1$.
\end{quote}
{\bf Theorem:} If $f(z)$ is analytic in and on a ball centered at $a$ of radius $r$, $B_r(a)$, then
$|f^{(n)}(a)| \leq {\frac {M n!} {r^n}}$, where  $|f(z)| \leq M, z \in B_r(a)$.
\begin{quote}
\emph{Proof:}
Use the Cauchy integral formula.
\end{quote}
{\bf Theorem:} If $f(z)$ is bounded and analytic in the plane, $f(z)$ is a constant.
\begin{quote}
\emph{Proof:}
$f(b) - f(a) = {\frac {b-a} {2 \pi i}} \int_{B_r(a)} {\frac {f(z)} {(z-a)(z-b)}} dz$.
So $|f(b) - f(a)| \leq {\frac {2|b-a| M} {r}}$; let $r \rightarrow \infty$.
\end{quote}
{\bf Rouche's Theorem:} If $f(z), g(z)$ are analytic 
in and on a simple closed curve $C$
and $|f(z)|>|g(z)|$ on $C$ then
$f(z)$ and $f(z)+g(z)$ have the same number of zeros in $C$.
\begin{quote}
\emph{Proof:}
Let $g(z)= F(z)f(z)$ so $|F(z)|<1$.
$\Delta N= 
{\frac 1 {2 \pi i}} \int_{\cal C} {\frac {f'(z)+g'(z)} {f(z)+g(z)}} dz -
{\frac 1 {2 \pi i}} \int_{\cal C} {\frac {f'(z)} {f(z)}} dz=
{\frac 1 {2 \pi i}} \int_{\cal C} {\frac {f'(z)+F'(z)f(z)+F(z)f'(z))} {f(z)(1+F(z))}} dz-
{\frac 1 {2 \pi i}} \int_{\cal C} {\frac {f'(z)} {f(z)}} dz=
{\frac 1 {2 \pi i}} \int_{\cal C} {\frac {F'(z)} {(1+F(z))}} dz$.  Since
$|F(z)|<1$, $(1+F(z))(1-F(z)+F^2(z)-F^3(z)+ \ldots $,
$\Delta N= 
{\frac 1 {2 \pi i}} \int_{\cal C} {\frac {F'(z)} {(1+F(z))}} dz=
{\frac 1 {2 \pi i}} \int_{\cal C} F'(z) (1-F(z)+F^2(z)- \ldots) dz=
{\frac 1 {2 \pi i}} \int_{\cal C} F'(z)  dz-
{\frac 1 {2 \pi i}} \int_{\cal C} F'(z) F(z) dz+
{\frac 1 {2 \pi i}} \int_{\cal C} F'(z) F^2(z) dz- \ldots
$ and each of these integrals is $0$.  Thus $\Delta N= 0$ and the theorem holds by
the previous result.
\end{quote}
{\bf Definition:}  A complex function, $f(z)$, is \emph{holomorphic} if it is
differentiable everywhere on ${\mathbb C}$.
A complex function, $f(z)$, has a \emph{removeable singularity} at
$a$ if $f(a)$ is undefined but there is a choice $b=f(a)$ which makes $f$ holomorphic.
A complex function, $f(z)$, has an \emph{essential singularity} at $a$ if $f(a)$ is neither
a pole nor a removeable singularity.
\\
\\
{\bf Theorem:}  
An analytic function comes arbitrarily close to any value in ${\mathbb C}$ in every neighborhood of an
essential singularity.
\begin{quote}
\end{quote}
{\bf Maximum Modulus Theorem:} If $f(z)$ is analytic inside and on a region enclosed by a curve
${\cal C}$ then the point with maximum modulus lies on ${\cal C}$.
\begin{quote}
\emph{Proof:}
Suppose $|f|$ achieved its maximum at $a$ inside ${\cal C}$ and $f(a) = M$. If $f$ is not
constant, we can choose a $B_r(a)$ for which $|f(x)| < M$ for some $x \in B_r(a)$.
${\frac 1 {2 \pi i}} \int_{B_r(a)} {\frac {f(z)}{z-a}} dz = f(a) = M$
${\frac 1 {2 \pi}} |\int_{B_r(a)} {\frac {f(z)}{z-a}} dz| = |f(a)| = M$. So,
${\frac 1 {2 \pi}} \int_{0}^{2 \pi} |{\frac {f(z)}{z-a}} dz| \geq  M$. This is impossible,
since $|f(x)| < M$ for some $x$.
\end{quote}
{\bf Laurent's Theorem:} If $f(z)$ is analytic inside an annular region (but
not necessarily in the whole disk) ${\cal A} = \{ r \leq {z-a} \leq R \}$ 
then  $f(z)= \sum_{n= - \infty}^{\infty} c_n (z-a)^n$ and
$c_n= {\frac 1 {2 \pi i}} \int_{{\cal C}(R)} {\frac {f(z)}{(z-a)^{n+1}}} dz, n \geq 0$ while
$c_n= {\frac 1 {2 \pi i}} \int_{{\cal C}(r)} f(z) (z-a)^{n-1} dz, n < 0$.
\begin{quote}
\emph{Proof:}
By Cauchy,
$f(z)= {\frac 1 {2 \pi i}} \int_{{\cal C}(R)} {\frac {f(w)}{w-z)}} dz -
{\frac 1 {2 \pi i}} \int_{{\cal C}(r)} {\frac {f(w)}{w-z)}} dz$.
${\frac 1 {w-z}}=
{\frac 1 {w-a} } +
{\frac {(z-a)} {(w-a)^2}}+
{\frac {(z-a)^2} {(w-a)^3}}+ \ldots +
{\frac {(z-a)^n} {(w-a)^{n}}} {\frac 1 {w-z}}$ and
$-{\frac 1 {w-z}}=
{\frac 1 {z-a} } (1 +
{\frac {(w-a)} {(z-a)}}+
({\frac {(w-a)} {(z-a)}})^2+ \ldots +
({\frac {(w-a)} {(z-a)}})^{n-1})+ 
({\frac {(w-a)} {(z-a)}})^{n} {\frac 1 {z-w}}$.  Further,
$|{\frac {w-a}{z-a}}|= \kappa < 1$.  So
$
{\frac 1 {2 \pi i}} \int_{{\cal C}(R)} {\frac {f(w)} {w-z}} dw=
{\frac 1 {2 \pi i}} \int_{{\cal C}(R)} {\frac {f(w)} {w-a}} dw +
{\frac {z-a} {2 \pi i}} \int_{{\cal C}(R)} {\frac {f(w)} {w-a}} dw +
{\frac {(z-a)^2} {2 \pi i}} \int_{{\cal C}(R)} {\frac {f(w)} {(w-a)^2}} dw + \ldots +
{\frac {(z-a)^n} {2 \pi i}} \int_{{\cal C}(R)} {\frac {f(w)} {(w-a)^n}} dw + U_n$  where
$U_n= {\frac 1 {2 \pi i}} \int_{{\cal C}(R)} ({\frac {z-a} {w-a}})^n{\frac {f(w)} {(w-z)}} dw$
and
$
-{\frac 1 {2 \pi i}} \int_{{\cal C}(r)} {\frac {f(w)} {w-z}} dw=
{\frac 1 {2 \pi i}} \int_{{\cal C}(r)} {\frac {f(w)} {z-a}} dw +
{\frac 1 {2 \pi i}} \int_{{\cal C}(r)} f(w) {\frac {(w-a)} {(z-a)^2}} +
{\frac 1 {2 \pi i}} \int_{{\cal C}(r)} f(w) {\frac {(w-a)^2} {(z-a)^3}} + \ldots +
{\frac 1 {2 \pi i}} \int_{{\cal C}(r)} f(w) {\frac {(w-a)^{n-1}} {(z-a)^n}} + \ldots +
+ V_n$  
where
$V_n= {\frac 1 {2 \pi i}} \int_{{\cal C}(r)} ({\frac {w-a} {z-a}})^n{\frac {f(w)} {(z-w)}} dw$.
$|U_n| \leq  {\frac {\kappa^n M R} {R- |z-a|}}$ and
$|V_n| \leq  {\frac {\kappa^n M r} {|z-a|-r}}$.
\end{quote}
{\bf Residue Theorem:}
$\int_{\cal C} f(z) dz = 2 \pi i (a_{-1} + b_{-1} + ... )$.
\begin{quote}
\end{quote}
